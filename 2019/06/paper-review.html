<!DOCTYPE html>
<html lang="en">
<head>
          <title>Ilia Ilmer - RiCNN and Rotation Robustness of ConvNets. A Paper Review</title>
        <meta charset="utf-8" />
        <meta name="generator" content="Pelican" />
        <link href="https://iliailmer.github.io/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="Ilia Ilmer Full Atom Feed" />
        <link href="https://iliailmer.github.io/feeds/posts.atom.xml" type="application/atom+xml" rel="alternate" title="Ilia Ilmer Categories Atom Feed" />




    <meta name="tags" content="review series" />
    <meta name="tags" content="deep learning" />
    <meta name="tags" content="computer vision" />

</head>

<body id="index" class="home">
        <header id="banner" class="body">
                <h1><a href="https://iliailmer.github.io/">Ilia Ilmer <strong>Algorithms and Coffee</strong></a></h1>
        </header><!-- /#banner -->
        <nav id="menu"><ul>
            <li><a href="https://iliailmer.github.io/pages/about.html">About</a></li>
            <li><a href="https://iliailmer.github.io/pages/cv.html">CV</a></li>
            <li><a href="https://iliailmer.github.io/pages/publications.html">Publications</a></li>
            <li><a href="https://iliailmer.github.io/pages/software.html">Software</a></li>
            <li><a href="https://iliailmer.github.io/pages/talks.html">Talks</a></li>
            <li class="active"><a href="https://iliailmer.github.io/category/posts.html">Posts</a></li>
        </ul></nav><!-- /#menu -->
<section id="content" class="body">
  <header>
    <h2 class="entry-title">
      <a href="https://iliailmer.github.io/2019/06/paper-review.html" rel="bookmark"
         title="Permalink to RiCNN and Rotation Robustness of ConvNets. A Paper Review">RiCNN and Rotation Robustness of ConvNets. A Paper Review</a></h2>
 
  </header>
  <footer class="post-info">
    <time class="published" datetime="2019-06-15T00:00:00-04:00">
      Sat 15 June 2019
    </time>
    <address class="vcard author">
      By           <a class="url fn" href="https://iliailmer.github.io/author/ilia-ilmer.html">Ilia Ilmer</a>
    </address>
    <div class="category">
        Category: <a href="https://iliailmer.github.io/category/posts.html">Posts</a>
    </div>
    <div class="tags">
        Tags:
            <a href="https://iliailmer.github.io/tag/review-series.html">review series</a>
            <a href="https://iliailmer.github.io/tag/deep-learning.html">deep learning</a>
            <a href="https://iliailmer.github.io/tag/computer-vision.html">computer vision</a>
    </div>
  </footer><!-- /.post-info -->
  <div class="entry-content">
    <p>Lately, I have been reading more papers on modern advances in deep learning in order to get a clear view of what problem I want to focus on during my PhD research.</p>
<p>There is a lot of information to process and an incredible amount of papers are being published from all over the world.</p>
<p>In order to keep up, I will do my best to document everything that I read in this weekly series of paper reviews. The aim is to post one review a week and go from there.</p>
<p>The first paper I will talk about is the one by <a href="https://arxiv.org/abs/1805.12301">Chidester, Do, and Ma</a> titled <strong>Rotation Equivariance and Invariance in Convolutional Neural Networks</strong>.</p>
<h1>What is the key problem?</h1>
<p>The advantage of convnets over other algorithms is in the amount of different features such network extracts from a given input. Convnets are a very powerful and form a very ubiquitous family of algorithms with various applications in industry.</p>
<p>When it comes to image classification, the same image or the same object in the image could be presented in various positions: it could be shifted left or right, and even rotated. The shift, or, <em>translation</em>, is something the network can withstand. The problem arises when the input is rotated.</p>
<p>If the network has never seen this rotated image, the result of classification will be wrong regardless of whether or not the net has seen the <em>un</em>-rotated original. This originates in the nature of the convolution: the operation of sliding the feature extracting kernel along the image (<a href="https://ezyang.github.io/convolution-visualizer/index.html">this</a> is an excellent depiction of convolution).</p>
<p><img alt="convolution" src="https://cdn-images-1.medium.com/max/1600/1*1okwhewf5KCtIPaFib4XaA.gif">
Convolution in its natural habitat: a blog post.</p>
<p>One common way of dealing with this is to rotate by a random angle images in the input. This is called <em>augmentation</em> and it increases the number of input data, which in turn may increase training time. Such trade-off is undesirable: why increase training time and sacrifice memory for a super-large network with hundreds of thousands of images already at hand?</p>
<p><em><strong>Side note:</strong> not to say that augmentation is a bad technique. Quite the <a href="http://cs231n.stanford.edu/reports/2017/pdfs/300.pdf">opposite</a>, it is a very powerful way to avoid overfitting.</em></p>
<p>So here is the problem: how can the network learn image transformation without explicitly seeing the transformed image during training?</p>
<h1>Rotation Equivariance</h1>
<p>In the second section of the paper, the authors propose a multi-stage approach to dealing with rotations.</p>
<p>Stage 1 is rotation equivariance, stage 2 is a rotation invariant layer in the network just before the fully-connected classifier block, and stage 3 is the fully-connected layer itself.</p>
<h3>Rotation Equivariance</h3>
<p>The term equivariance when applied to rotation transformation means the following: if a function
<img alt="F" src="http://mathurl.com/render.cgi?%5Cinlinemode%20%5Cmathcal%7BF%7D%5Cnocache"> acts on an input <img alt="x" src="http://mathurl.com/render.cgi?%5Cinlinemode%20x%5Cnocache"> then the result is<img alt="y" src="http://mathurl.com/render.cgi?%5Cinlinemode%20y%20%3D%20%5Cmathcal%7BF%7D%28x%29%5Cnocache">. If the input is "corrupted" by a transformation <img alt="T" src="http://mathurl.com/render.cgi?%5Cinlinemode%20%5Cmathrm%7BT%7D%5Cnocache"> (rotation, shift, etc.), then <em>equivariance with respect to</em> <img alt="T" src="http://mathurl.com/render.cgi?%5Cinlinemode%20%5Cmathrm%7BT%7D%5Cnocache"> implies existence of a transform <img alt="S" src="http://mathurl.com/render.cgi?%5Cinlinemode%20%5Cmathrm%7BS%7D%5Cnocache"> such that:</p>
<p><img alt="F(Tx)=S(F(x))" src="http://mathurl.com/render.cgi?%5Cinlinemode%20%5Cmathcal%7BF%7D%28%5Cmathrm%7BT%7Dx%7D%29%20%3D%20%5Cmathrm%7BS%7D%28%5Cmathcal%7BF%7D%28x%29%29%5Cnocache">.</p>
<p>The invariance property would look like this:</p>
<p><img alt="F(Tx) = F(x)" src="http://mathurl.com/render.cgi?%5Cinlinemode%20%5Cmathcal%7BF%7D%28%5Cmathrm%7BT%7Dx%7D%29%20%3D%20%5Cmathcal%7BF%7D%28x%29%5Cnocache">.</p>
<h1>Proposed Solution</h1>
<h3>Rotation of the Filters</h3>
<p>What the authors proposed is to connect rotation of the input with that of the feature extractor explicitly. To elaborate, the convolutional kernel is, essentially, rotated for a desired range of angles. At the same time, the image is split into conic regions, each region will have a designated rotated copy of the convolution kernel. Each rotated kernel is applied to the region.</p>
<p>This formulation opens up a new formalism: a conic convolution.</p>
<p><img alt="diagram" src="https://iliailmer.github.io/images/ricnn-paper-review/diagram.png">
Diagram of the proposed network by <a href="https://arxiv.org/abs/1805.12301">Chidester, Do, and Ma</a>.</p>
<p>The authors prove a very interesting property of this network. Essentially, the rotation equivariance property we stated still holds, according the results, however, <img alt="T" src="http://mathurl.com/render.cgi?%5Cinlinemode%20%5Cmathrm%7BT%7D%5Cnocache"> is equal to <img alt="F" src="http://mathurl.com/render.cgi?%5Cinlinemode%20%5Cmathcal%7BF%7D%5Cnocache">. (This is proven in Theorem 1 of the article.)</p>
<h3>Discrete Fourier transform (DFT)</h3>
<p>After that, the results of the conic section of the network need proceed to an additional section before the fully-connected one. It is required to preserve the rotation equivariance extracted by the conic portion before unravelling the tensors.</p>
<p>Such encoding of the equivariance is achieved through the DFT procedure. The authors note the cyclical property of the last convolutional with respect to rotation order. Applying  DFT to the output of this convolution yields a representation in which the rotation is "hard-coded".</p>
<p>Finally, this representation is passed into the fully connected layer.</p>
<h1>Conclusion</h1>
<p>I will not focus this review on the results of the work when applied to benchmark datasets, I believe it is only fair that one refers to the <a href="https://arxiv.org/abs/1805.12301">paper</a> itself for that.</p>
<p>Rotation equivariance and general robustness of neural networks to external peturbations is important and in applications such as medical imaging, where the data can be the same image from different angles (or with different transformations applied), a neural network must return a faulty result as the life of a patient is on the line.</p>
  </div><!-- /.entry-content -->
</section>
        <footer id="contentinfo" class="body">
                <address id="about" class="vcard body">
                Proudly powered by <a href="https://getpelican.com/">Pelican</a>,
                which takes great advantage of <a href="https://www.python.org/">Python</a>.
                </address><!-- /#about -->
        </footer><!-- /#contentinfo -->
</body>
</html>