<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Ilia Ilmer</title><link href="https://iliailmer.github.io/" rel="alternate"></link><link href="https://iliailmer.github.io/feeds/all.atom.xml" rel="self"></link><id>https://iliailmer.github.io/</id><updated>2021-07-25T00:00:00-04:00</updated><subtitle>Algorithms and Coffee</subtitle><subtitle>Algorithms and Coffee</subtitle><entry><title>First Month In GSoC</title><link href="https://iliailmer.github.io/2021/07/first-month-in-gsoc.html" rel="alternate"></link><published>2021-07-25T00:00:00-04:00</published><updated>2021-07-25T00:00:00-04:00</updated><author><name>Ilia Ilmer</name></author><id>tag:iliailmer.github.io,2021-07-25:/2021/07/first-month-in-gsoc.html</id><summary type="html">&lt;h1 id="project-updates"&gt;Project Updates&lt;/h1&gt;
&lt;p&gt;We slightly churned our project idea from the original algorithm implementation into an inclusion of a &lt;code&gt;StructuralIdentifiability.jl&lt;/code&gt; package develop by my colleague &lt;a href="https://pogudingleb.github.io/"&gt;Gleb Pogudin&lt;/a&gt;. The package is currently part of SciML with more updates to come!&lt;/p&gt;
&lt;p&gt;Here is a list of things it can do:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;check local …&lt;/li&gt;&lt;/ul&gt;</summary><content type="html">&lt;h1 id="project-updates"&gt;Project Updates&lt;/h1&gt;
&lt;p&gt;We slightly churned our project idea from the original algorithm implementation into an inclusion of a &lt;code&gt;StructuralIdentifiability.jl&lt;/code&gt; package develop by my colleague &lt;a href="https://pogudingleb.github.io/"&gt;Gleb Pogudin&lt;/a&gt;. The package is currently part of SciML with more updates to come!&lt;/p&gt;
&lt;p&gt;Here is a list of things it can do:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;check local identifiability of parameters&lt;/li&gt;
&lt;li&gt;check global identifiability of parameters&lt;/li&gt;
&lt;li&gt;check for identifiable functions (work-in-progress feature)&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id="future-directions"&gt;Future Directions&lt;/h1&gt;
&lt;p&gt;We plan to add more tutorials, finalize registering the package, and make it compatible with ODE systems defined in other SciML projects!&lt;/p&gt;</content><category term="Posts"></category><category term="Julia"></category><category term="GSoC"></category></entry><entry><title>Structural Identifiability Toolbox</title><link href="https://iliailmer.github.io/2021/07/structural-identifiability-toolbox.html" rel="alternate"></link><published>2021-07-25T00:00:00-04:00</published><updated>2021-07-25T00:00:00-04:00</updated><author><name>Ilia Ilmer</name></author><id>tag:iliailmer.github.io,2021-07-25:/2021/07/structural-identifiability-toolbox.html</id><summary type="html">&lt;h1 id="introduction"&gt;Introduction&lt;/h1&gt;
&lt;p&gt;In this repository, I will describe our recently-released Structural Identifiability Toolbox, a web-based application for assessing parameter identifiability of differential models.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://maple.cloud/app/6509768948056064/"&gt;Click here&lt;/a&gt; to checkout the application! Read on to learn more.&lt;/p&gt;
&lt;h1 id="why-is-it-better"&gt;Why is it better?&lt;/h1&gt;
&lt;p&gt;The program is fast, free, and is available in &lt;em&gt;any&lt;/em&gt; web-browser, including mobile …&lt;/p&gt;</summary><content type="html">&lt;h1 id="introduction"&gt;Introduction&lt;/h1&gt;
&lt;p&gt;In this repository, I will describe our recently-released Structural Identifiability Toolbox, a web-based application for assessing parameter identifiability of differential models.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://maple.cloud/app/6509768948056064/"&gt;Click here&lt;/a&gt; to checkout the application! Read on to learn more.&lt;/p&gt;
&lt;h1 id="why-is-it-better"&gt;Why is it better?&lt;/h1&gt;
&lt;p&gt;The program is fast, free, and is available in &lt;em&gt;any&lt;/em&gt; web-browser, including mobile. We take care of a lot stuff in the background letting the user worry only about their model definition without any technicalities.&lt;/p&gt;
&lt;h1 id="who-is-it-designed-for"&gt;Who is it designed for?&lt;/h1&gt;
&lt;p&gt;Simply put, if you are working with models based on ordinary differential equations and you wish to know structural identifiability properties of your models' parameters then this app is built for you!&lt;/p&gt;
&lt;p&gt;Knowing structural identifiability properties will help one set up better experiments to obtain data for the underlying process and extract parameter values correctly.&lt;/p&gt;
&lt;h1 id="what-can-it-do"&gt;What can it do?&lt;/h1&gt;
&lt;h2 id="individual-parameters"&gt;Individual Parameters&lt;/h2&gt;
&lt;p&gt;The application can answer questions about local or global identifiability parameters (including initial conditions): you provide the input system, choose the probability of correctness and, optionally, specify which parameter to check (by default it checks for all possible parameters). For this, the app is using SIAN algorithm[^1][^2] for details) which is fast, robust, and is correct with user-specified probability.&lt;/p&gt;
&lt;h2 id="parameter-combinations"&gt;Parameter Combinations&lt;/h2&gt;
&lt;p&gt;If a parameter is &lt;em&gt;non&lt;/em&gt;-identifiable, one may wish to seek an identifiable function that contains this parameter (and, possibly, others). Built with a brand new algorithm[^3], the app can quickly assess generators for all such functions. Moreover, we provide a way to assess whether 1 or more experiments are required to do so, this is called multi-experiment identifiability.&lt;/p&gt;
&lt;h1 id="references"&gt;References&lt;/h1&gt;
&lt;p&gt;[^1]: H. Hong, A. Ovchinnikov, G. Pogudin, C. Yap, &lt;a href="https://onlinelibrary.wiley.com/doi/abs/10.1002/cpa.21921"&gt;Global Identifiability of Differential Models&lt;/a&gt;, Communications on Pure and Applied Mathematics, Volume 73, Issue 9, Pages 1831-1879, 2020&lt;/p&gt;
&lt;p&gt;[^2]: H. Hong, A. Ovchinnikov, G. Pogudin, C. Yap, &lt;a href="https://doi.org/10.1093/bioinformatics/bty1069"&gt;SIAN: Software for Structural Identifiability Analysis of ODE Models&lt;/a&gt; Bioinformatics, Volume 35, Issue 16, Pages 2873–2874, 2019&lt;/p&gt;
&lt;p&gt;[3]: &lt;a href="https://arxiv.org/abs/2004.07774"&gt;Computing All Identifiable Functions of ODE Models&lt;/a&gt;, arXiv:2004.07774&lt;/p&gt;</content><category term="Posts"></category><category term="Maple"></category><category term="Symbolic Computing"></category></entry><entry><title>My Google Summer of Code Project</title><link href="https://iliailmer.github.io/2021/06/my-google-summer-of-code-project.html" rel="alternate"></link><published>2021-06-08T00:00:00-04:00</published><updated>2021-06-08T00:00:00-04:00</updated><author><name>Ilia Ilmer</name></author><id>tag:iliailmer.github.io,2021-06-08:/2021/06/my-google-summer-of-code-project.html</id><summary type="html">&lt;h1 id="about-the-project"&gt;About The Project&lt;/h1&gt;
&lt;h2 id="problem-formulation"&gt;Problem Formulation&lt;/h2&gt;
&lt;p&gt;The problem of parameter identifiability is one of the most crucial issues arising in systems biology. To take a look at a problem of identifiability, we must first describe a setting in which it arises. Systems biology deals with biological processes that are described by …&lt;/p&gt;</summary><content type="html">&lt;h1 id="about-the-project"&gt;About The Project&lt;/h1&gt;
&lt;h2 id="problem-formulation"&gt;Problem Formulation&lt;/h2&gt;
&lt;p&gt;The problem of parameter identifiability is one of the most crucial issues arising in systems biology. To take a look at a problem of identifiability, we must first describe a setting in which it arises. Systems biology deals with biological processes that are described by ordinary differential equations (ODEs). These equations, in essence, describe mathematically the model’s evolution through time. Each such theoretical model can have dedicated inputs and outputs. An example of an input is a catalyst for chemical reaction. An example of an output could be a measurement done by the chemist.&lt;/p&gt;
&lt;p&gt;In addition to input and output, the model has states and parameters. States are quantities whose time evolution is being considered, while parameters are values that come from intrinsic properties of the system. For example, in a model of population growth such as the Lotka-Volterra model, a species’ intrinsic growth rate is a parameter but the population density is a state.&lt;/p&gt;
&lt;p&gt;Now we are ready to pose the identifiability question: given an input and an output as functions of time, can we recover information about states and parameters?&lt;/p&gt;
&lt;p&gt;The answer to that question can be one of three kinds: &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;No, the parameters or states of the system cannot be recovered from given inputs or outputs&lt;/li&gt;
&lt;li&gt;Yes, we can uniquely recover parameters and states&lt;/li&gt;
&lt;li&gt;Yes, we can recover parameters and states but up to finitely many values.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Point 1 corresponds to non-identifiability. This means that an experiment with given inputs outputs cannot help the researcher recover the parameters or states. Answers 2 and 3 correspond to two kinds of identifiability: global and local respectively.&lt;/p&gt;
&lt;p&gt;The above problem formulation refers to structural identifiability, which is a theoretical property. Another type of identifiability is practical which studies recovery of parameters from given data.&lt;/p&gt;
&lt;h2 id="the-project"&gt;The Project&lt;/h2&gt;
&lt;p&gt;This summer I will be working on an implementation of an algorithm for testing local (see part 3 above) identifiability which will become part of the &lt;code&gt;ModelingToolkit.jl&lt;/code&gt; package.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;ModelingToolkit.jl&lt;/code&gt; and &lt;code&gt;Symbolics.jl&lt;/code&gt; make a significant contribution to the area of symbolic computation for Julia language. It is currently an open problem to enhance these packages with the capabilities of structural identifiability analysis. This project consists of coding the algorithms for local and global identifiability problems using Julia Programming Language and &lt;code&gt;Symbolics.jl&lt;/code&gt; with &lt;code&gt;ModelingToolkit.jl&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The general direction of solving this problem is to begin with fast and efficient (polynomial time) algorithm implementation. A good starting point is &lt;a href="https://www.lifl.fr/~sedoglav/Load/Sedoglavic2002.pdf"&gt;this&lt;/a&gt; algorithm for local identifiability tests that relies on power series solutions.&lt;/p&gt;
&lt;p&gt;Later on (and, more importantly, with enough time) we can enhance the functionality to allow tests for global identifiability checking.&lt;/p&gt;</content><category term="Posts"></category><category term="Julia"></category><category term="GSOC"></category></entry><entry><title>How I had to translate Matlab code into Maple</title><link href="https://iliailmer.github.io/2020/08/matlab-2-maple.html" rel="alternate"></link><published>2020-08-18T00:00:00-04:00</published><updated>2020-08-18T00:00:00-04:00</updated><author><name>Ilia Ilmer</name></author><id>tag:iliailmer.github.io,2020-08-18:/2020/08/matlab-2-maple.html</id><summary type="html">&lt;p&gt;In this short post, I wanted to point out one interesting application of regular expressions I had to work on for my PhD research project. The code was meant as a technical tool to help tranlate some ordingary differential equation models from numerical (Matlab) to symbolic (Maple) code.&lt;/p&gt;
&lt;h2 id="the-original-code"&gt;The original …&lt;/h2&gt;</summary><content type="html">&lt;p&gt;In this short post, I wanted to point out one interesting application of regular expressions I had to work on for my PhD research project. The code was meant as a technical tool to help tranlate some ordingary differential equation models from numerical (Matlab) to symbolic (Maple) code.&lt;/p&gt;
&lt;h2 id="the-original-code"&gt;The original code&lt;/h2&gt;
&lt;p&gt;The original *.m files were pulled from &lt;a href="https://www.ebi.ac.uk/biomodels/"&gt;this&lt;/a&gt; webpage using &lt;code&gt;wget&lt;/code&gt; and their own API. Ordingary differential equation (ODE) models in those files contain a special function called &lt;code&gt;xdot&lt;/code&gt;. It returns an array of &lt;code&gt;n&lt;/code&gt; elements, which form right-hand side of an ODE.&lt;/p&gt;
&lt;p&gt;The function is usually defined in the form&lt;/p&gt;
&lt;p&gt;&lt;code&gt;m
function xdot=f(x,t)
    % define parameters as
    C = 1.0;
    % ...
    xdot = zeros(..., ...);
    % define each xdot(i) separately
end&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;What I wanted to see in the maple code was the following:&lt;/p&gt;
&lt;p&gt;```py&lt;/p&gt;
&lt;h1 id="define-parameters-as-symbolic-constants"&gt;define parameters as symbolic constants&lt;/h1&gt;
&lt;p&gt;C := C:&lt;/p&gt;
&lt;h1 id="define-system-of-odes-as-array"&gt;define system of odes as array&lt;/h1&gt;
&lt;p&gt;sigma := [
    diff(x1(t), t) = &amp;lt;...&amp;gt;,
    &amp;lt;...&amp;gt;
    diff(xn(t), t) = &amp;lt;...&amp;gt;
]:
```&lt;/p&gt;
&lt;p&gt;The best way to solve it I saw was to use regular expressions.&lt;/p&gt;
&lt;h2 id="step-by-step"&gt;Step by step&lt;/h2&gt;
&lt;p&gt;Firstly, I had to get rid of Matlab comment and turn them into Maple compatible ones, hence the line&lt;/p&gt;
&lt;p&gt;&lt;code&gt;py
out_program = re.findall(
                r"function xdot=f\(x,t\)(.*?)end", content, re.DOTALL
            )[0].replace("%", "#")&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;After that, we want to look at &lt;code&gt;if&lt;/code&gt; statements. In Maple, conditional structure like &lt;code&gt;if&lt;/code&gt; statements are written as&lt;/p&gt;
&lt;p&gt;&lt;code&gt;pascal
if &amp;lt;condition&amp;gt; then &amp;lt;code&amp;gt; end:&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;To do that, we utilize groups: &lt;code&gt;(..)&lt;/code&gt;. The regex is&lt;/p&gt;
&lt;p&gt;&lt;code&gt;py
out_program = re.sub(
                r"if(\(\w*\))(.*;)end",
                r"if \1 then \2\nend if:",
                out_program,
                flags=re.DOTALL,
            )&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;if(\(\w*\))(.*;)end&lt;/code&gt; regex gets the condition &lt;code&gt;\(\w*\)&lt;/code&gt; and the code (.*;) between &lt;code&gt;if&lt;/code&gt; / &lt;code&gt;end&lt;/code&gt; to place those between &lt;code&gt;if&lt;/code&gt;, &lt;code&gt;then&lt;/code&gt;, &lt;code&gt;end&lt;/code&gt; in positions marked by &lt;code&gt;\1&lt;/code&gt; and &lt;code&gt;\2&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Remeber, that we do not want to have &lt;code&gt;xdot(i)=...&lt;/code&gt; assigned manually anymore in Maple, we want to see Maple syntax: &lt;code&gt;diff(x(t),t) = ...&lt;/code&gt;, so we do the following regex:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;py
out_program = re.sub(
                r"xdot\((\d+)\) \=( .*);", r"\ndiff(x\1(t), t) = \2,", out_program
            )&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Again, notice the groups that capture stuff we want to preserve, namely the index of &lt;code&gt;xdot&lt;/code&gt; and the right-hand sides.&lt;/p&gt;
&lt;p&gt;Next few lines do some cosmetic work, namely, rename any &lt;code&gt;x(i)&lt;/code&gt; appearance into &lt;code&gt;xi(t)&lt;/code&gt;, then make all variable assingments symbolic constants (i.e. if we have &lt;code&gt;c=0&lt;/code&gt; we want to have &lt;code&gt;c:=c&lt;/code&gt;). Finally, if we have Matlab assignments that do not use constants (i.e. &lt;code&gt;c=0; x = c+x;&lt;/code&gt;) we want to keep them (i.e. &lt;code&gt;c:=c: x:=c+x:&lt;/code&gt;).&lt;/p&gt;
&lt;p&gt;&lt;code&gt;py
out_program = re.sub(r"x\((\d+)\)", r"x\1(t)", out_program) # x(i) -&amp;gt; xi(t)
out_program = re.sub(r"(\w+)\=\d*\..*", r"\1:=\1:", out_program) # c=NUMBER -&amp;gt; c:=c:
out_program = re.sub(r"(\w+)\=(.*);", r"\1:=\2:", out_program) # Left-side = ANYTHING NOT METNIONED ABOVE -&amp;gt; same but with := sign&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Finally, putting it all together we can run:&lt;/p&gt;
&lt;p&gt;```py
import re
from glob import glob
from tqdm.auto import tqdm&lt;/p&gt;
&lt;p&gt;files = glob("files/&lt;em&gt;/&lt;/em&gt;/*.m")&lt;/p&gt;
&lt;p&gt;for i in tqdm(range(len(files))):
    with open(files[i], "r") as f:
        try:
            content = f.read()
        except:
            print(files[i], "could not read")
        try:
            out_program = re.findall(
                r"function xdot=f(x,t)(.&lt;em&gt;?)end", content, re.DOTALL
            )[0].replace("%", "#")
            out_program = re.sub(
                r"if((\w&lt;/em&gt;))(.&lt;em&gt;;)end",
                r"if \1 then \2\nend if:",
                out_program,
                flags=re.DOTALL,
            )
            out_program = re.sub(
                r"xdot((\d+)) \=( .&lt;/em&gt;);", r"\ndiff(x\1(t), t) = \2,", out_program
            )
            out_program = re.sub(r"(xdot=zeros.*)", r"# \1", out_program) # comment out declaration of xdot&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;        out_program = re.sub(r"x\((\d+)\)", r"x\1(t)", out_program)
        out_program = re.sub(r"(\w+)\=\d*\..*", r"\1:=\1:", out_program)
        out_program = re.sub(r"(\w+)\=(.*);", r"\1:=\2:", out_program)
        # cosmetic work to make maple run and not complain about trailing comma
        out_program = re.sub(
            r"(diff.*)", r"sigma := [\n\1]:", out_program, flags=re.DOTALL
        ).replace(",\n]", "\n]")

        outname = files[i].split(".")[0] + ".mpl"

        with open(outname, "w") as output:
            output.write(out_program)
        import os

        os.system("mkdir -p new_examples")
        os.system(f"cp {outname} new_examples")
    except:
        print(files[i], "Index not Found.")
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;```&lt;/p&gt;
&lt;p&gt;Some stuff really specific to our project was omitted for brevity, but one can definitely add any other Maple/Matlab interaction here.&lt;/p&gt;</content><category term="Posts"></category><category term="python"></category><category term="regular expressions"></category><category term="matlab"></category><category term="maple"></category></entry><entry><title>NumPy-Learn, A Homemade Machine Learning Library</title><link href="https://iliailmer.github.io/2020/06/numpy-learn.html" rel="alternate"></link><published>2020-06-14T00:00:00-04:00</published><updated>2020-06-14T00:00:00-04:00</updated><author><name>Ilia Ilmer</name></author><id>tag:iliailmer.github.io,2020-06-14:/2020/06/numpy-learn.html</id><summary type="html">&lt;p&gt;In this post, I expand on a little class/self-teaching project that I did during the Spring 2020 semester.&lt;/p&gt;
&lt;h1 id="numpy-learn-a-homemade-machine-learning-library"&gt;NumPy-Learn: A Homemade Machine Learning Library&lt;/h1&gt;
&lt;h2 id="organization"&gt;Organization&lt;/h2&gt;
&lt;p&gt;In this section we will discuss the main organization of the library:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;How the layers are built&lt;/li&gt;
&lt;li&gt;How loss functions work&lt;/li&gt;
&lt;li&gt;How a stochastic …&lt;/li&gt;&lt;/ul&gt;</summary><content type="html">&lt;p&gt;In this post, I expand on a little class/self-teaching project that I did during the Spring 2020 semester.&lt;/p&gt;
&lt;h1 id="numpy-learn-a-homemade-machine-learning-library"&gt;NumPy-Learn: A Homemade Machine Learning Library&lt;/h1&gt;
&lt;h2 id="organization"&gt;Organization&lt;/h2&gt;
&lt;p&gt;In this section we will discuss the main organization of the library:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;How the layers are built&lt;/li&gt;
&lt;li&gt;How loss functions work&lt;/li&gt;
&lt;li&gt;How a stochastic gradient descent optimizer was built&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;After that, we introduce the class for building the neural net itself and explain how everything ties together. We conclude by performance analysis on a simple MNIST program.&lt;/p&gt;
&lt;p&gt;Let us agree on convention similar to that of PyTorch library: we will call the main datatype &lt;code&gt;Tensor&lt;/code&gt; instead of &lt;code&gt;array&lt;/code&gt;, as follows:
&lt;code&gt;py
from numpy import ndarray as Tensor&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;This is to adhere to accepted aesthetics of most modern neural network libraries and nothing more. All methods are purely using &lt;code&gt;numpy&lt;/code&gt; or &lt;code&gt;scipy&lt;/code&gt;.&lt;/p&gt;
&lt;h3 id="linear-layer"&gt;Linear Layer&lt;/h3&gt;
&lt;p&gt;Inspired by PyTorch, the naming convention here is the preserved. The design of the layer is also similar to PyTorch: the class &lt;code&gt;Linear&lt;/code&gt; will have a &lt;code&gt;forward&lt;/code&gt; and a &lt;code&gt;backward&lt;/code&gt; methods. The former will represent the forward pass, that is, the passing of the input data through the layer towards the next. The latter is responsible for backward propagation of the gradient.&lt;/p&gt;
&lt;h4 id="forward-pass"&gt;Forward Pass&lt;/h4&gt;
&lt;p&gt;Linear layer essentially represents matrix multiplication of the input data &lt;span class="math"&gt;\(x\)&lt;/span&gt; by a weight matrix &lt;span class="math"&gt;\(W\)&lt;/span&gt; with addition of bias &lt;span class="math"&gt;\(b\)&lt;/span&gt;:&lt;/p&gt;
&lt;div class="math"&gt;$$\mathrm{L}(x) = xW + b.$$&lt;/div&gt;
&lt;p&gt;We require that the size of the input data was of the format &lt;span class="math"&gt;\(batch\times input~features\)&lt;/span&gt;, for instance if the input data has 784 pixel values, for a batch of 100 images the size of &lt;span class="math"&gt;\(x\)&lt;/span&gt; would be &lt;span class="math"&gt;\(100\times 784\)&lt;/span&gt; and the size of &lt;span class="math"&gt;\(W\)&lt;/span&gt; would be &lt;span class="math"&gt;\(784\times out~features\)&lt;/span&gt;, while &lt;span class="math"&gt;\(b\)&lt;/span&gt; is of the shape &lt;span class="math"&gt;\(out~features\times 1\)&lt;/span&gt;. Here we rely on &lt;code&gt;numpy&lt;/code&gt; broadcasting the value of bias onto the resulting matrix &lt;span class="math"&gt;\(xW\)&lt;/span&gt; when adding &lt;span class="math"&gt;\(b\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;In code, we define it as follows:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;py
def forward(self, x: Tensor) -&amp;gt; Tensor:
        self.input = x
        return x @ self.W + self.b&lt;/code&gt;&lt;/p&gt;
&lt;h4 id="gradient"&gt;Gradient&lt;/h4&gt;
&lt;p&gt;In the forward pass, we computed the matrix product. Next, we need to evaluate the rate of change of the output of the current layer with respect to the input. Note, that due to the chain rule, the gradient flows from right (output) to left (input) as a product.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;backward&lt;/code&gt; method utilizes chainrule. It accepts the gradient from the layer &lt;span class="math"&gt;\(l+1\)&lt;/span&gt;, uses it to find the derivatives of the current layer's output with respect to &lt;span class="math"&gt;\(W\)&lt;/span&gt; and &lt;span class="math"&gt;\(b\)&lt;/span&gt; and finally, passes it along multiplying by the derivative of its output w.r.t. &lt;span class="math"&gt;\(x\)&lt;/span&gt;, the input.&lt;/p&gt;
&lt;p&gt;Mathematically, this is the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The loss's derivatives w.r.t. weights are &lt;div class="math"&gt;$$\frac{\partial E}{\partial W^{l}_{ij}}=\sum\limits_{\text{input-output pair}}\delta^l_i out^{l-1}_j$$&lt;/div&gt;.&lt;/li&gt;
&lt;li&gt;Here, &lt;span class="math"&gt;\(\delta^l_i\)&lt;/span&gt; is the error of the &lt;span class="math"&gt;\(l\)&lt;/span&gt;th layer for &lt;span class="math"&gt;\(i\)&lt;/span&gt;th node: &lt;div class="math"&gt;$$\delta^l_i=g'_{out}(a_i^l)\sum\limits_k W^{l+1}_{ik}\delta^{l+1}_{k}$$&lt;/div&gt;, where &lt;span class="math"&gt;\(g\)&lt;/span&gt; is the activation function.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;These equations are written in a different shape convention, but we can take care of that in the code.&lt;/p&gt;
&lt;p&gt;The derivative of &lt;span class="math"&gt;\(xW+b\)&lt;/span&gt; w.r.t. &lt;span class="math"&gt;\(W\)&lt;/span&gt; is &lt;span class="math"&gt;\(x^T\)&lt;/span&gt;. The derivative of &lt;span class="math"&gt;\(xW+b\)&lt;/span&gt; w.r.t. to &lt;span class="math"&gt;\(b\)&lt;/span&gt; is an identity matrix. Therefore, let &lt;code&gt;grad&lt;/code&gt; be the gradient (error) received from &lt;span class="math"&gt;\((l+1)\)&lt;/span&gt;th layer, then we can define the &lt;code&gt;backward&lt;/code&gt; method as below:
&lt;code&gt;py
def backward(self, grad: Tensor) -&amp;gt; Tensor:
        # input_feat by batch_size @ batch_size by out_features
        self.dydw = self.input.T @ grad
        # we sum across batches and get shape (out_features)
        self.dydb = grad.sum(axis=0)
        # output must be of shape (batch_size, out_features)
        return grad @ self.W.T&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Now we are ready to present the fully defined Linear Layer code below:&lt;/p&gt;
&lt;p&gt;```python
import numpy as np
from numpy import ndarray as Tensor&lt;/p&gt;
&lt;p&gt;class Linear:
    """A linear layer."""&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;def __init__(self, in_features: int, out_features: int):
    """Initialize a linear layer with weights and biases."""
    self.W = np.random.randn(in_features, out_features)

    self.b = np.random.randn(out_features)

def forward(self, x: Tensor) -&amp;gt; Tensor:
    """Compute forward pass, return W @ x + b.

    Arguments:
        W: the weight Tensor of shape (in_featuers, out_features)
        b: the bias vector of shape (out_features,)
        x: the input of shape (batch_size, in_features)

    Returns:
        A tensor of shape (batch_size, out_features)

    """
    self.input = x
    return x @ self.W + self.b

def backward(self, grad: Tensor) -&amp;gt; Tensor:
    """Propagate the gradient from the l+1 layer to l-1 layer.

    Arguments:
        grad: the tensor gradients from the l+1 layer to be
              propagated, shape: (batch_size, out_features).

    References:
        http://home.agh.edu.pl/~vlsi/AI/backp_t_en/backprop.html

    """
    # in_feat by batch_size @ batch_size by out_feat
    self.dydw = self.input.T @ grad
    # we sum across batches and get shape (out_features)
    self.dydb = grad.sum(axis=0)
    # output must be of shape (batch_size, out_features)
    return grad @ self.W.T

def __call__(self, x: Tensor) -&amp;gt; Tensor:
    """Peform forward pass on `__call__`."""
    return self.forward(x)

def __repr__(self) -&amp;gt; str:
    """Print a representation for Jupyter/IPython."""
    return f"""Linear Layer:\n\tWeight: {self.W.shape}"""\
        + f"""\n\tBias: {self.b.shape}"""
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;```&lt;/p&gt;
&lt;h3 id="layers-with-activation-functions"&gt;Layers with Activation Functions&lt;/h3&gt;
&lt;p&gt;We define separate layers for activation functions, similarly to the way PyTorch handles those. We only define two here: ReLU and Sigmoid.&lt;/p&gt;
&lt;p&gt;ReLU is defined as &lt;/p&gt;
&lt;div class="math"&gt;$$f(x) = \max\{0, x\}$$&lt;/div&gt;
&lt;p&gt; and Sigmoid is defined as &lt;/p&gt;
&lt;div class="math"&gt;$$\sigma(x) = \frac{1}{1+\exp(-x)}.$$&lt;/div&gt;
&lt;p&gt;Their derivatives are defined as &lt;/p&gt;
&lt;div class="math"&gt;$$(\nabla f)(t) = 0 \text{ if } t=0\text{, else }t$$&lt;/div&gt;
&lt;div class="math"&gt;$$(\nabla \sigma)(t) = \sigma(t)(1-\sigma(t))$$&lt;/div&gt;
&lt;p&gt;The respective classes are defined below&lt;/p&gt;
&lt;p&gt;```python
def sigmoid(x: Tensor) -&amp;gt; Tensor:
    """Calculate the sigmoid function of x."""
    return 1/(1+np.exp(-x))&lt;/p&gt;
&lt;p&gt;def sigmoid_prime(x: Tensor) -&amp;gt; Tensor:
    """Calculate the d/dx of sigmoid function of x."""
    return sigmoid(x)*(1-sigmoid(x))&lt;/p&gt;
&lt;p&gt;class ReLU:
    """ReLU class."""&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;def __init__(self):
    """Initialize the ReLU instance."""

def forward(self, x: Tensor) -&amp;gt; Tensor:
    """Compute the activation in the forward pass.

    Arguments:
        x: Tensor of inputs, shape (batch_size, in_features)

    Returns:
        Tensor of shape (batch_size, in_features)

    """
    return np.maximum(x, 0)

def backward(self, grad: Tensor) -&amp;gt; Tensor:
    """Compute the gradient and pass it backwards.

    Arguments:
        grad: Tensor of gradients of shape (batch_size, out_features)

    Returns:
        Tensor of shape (batch_size, out_features)

    """
    return np.maximum(grad, 0)

def __call__(self, x: Tensor) -&amp;gt; Tensor:
    """Peform forward pass on `__call__`."""
    return self.forward(x)

def __repr__(self) -&amp;gt; str:
    """Print a representation of ReLU for Jupyter/IPython."""
    return """ReLU()"""
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;class Sigmoid:
    """Sigmoid class."""&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;def __init__(self):
    """Initialize the instance.

    We add the main function for activation and its derivative function.
    """
    self.sigmoid = sigmoid
    self.sigmoid_prime = sigmoid_prime

def forward(self, x: Tensor) -&amp;gt; Tensor:
    """Compute the activation in the forward pass.

    Arguments:
        x: Tensor of inputs with shape(batch_size, in_features)

    Returns:
        Tensor of shape(batch_size, in_features)

    """
    self.input = x
    return self.sigmoid(x)

def backward(self, grad: Tensor):
    """Compute the gradient and pass it backwards.

    Arguments:
        grad: Tensor of gradients with shape(batch_size, out_features)

    Returns:
        Tensor of shape(in_features, out_features)

    """
    return self.sigmoid_prime(self.input) * grad

def __call__(self, x: Tensor) -&amp;gt; Tensor:
    """Peform forward pass on `__call__`."""
    return self.forward(x)

def __repr__(self) -&amp;gt; str:
    """Print a representation of Sigmoid for Jupyter/IPython."""
    return """Sigmoid()"""
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;```&lt;/p&gt;
&lt;p&gt;In addition to Sigmoid and ReLU, we also import &lt;code&gt;softmax&lt;/code&gt; activation function from &lt;code&gt;scipy&lt;/code&gt;. In my experiments, I found that this is the most stable implementation, so I did not want to run into &lt;a href="https://en.wikipedia.org/wiki/Not_invented_here"&gt;"not invented here"&lt;/a&gt; problem.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;softmax&lt;/code&gt; is defined as follows:&lt;/p&gt;
&lt;div class="math"&gt;$$\mathcal{S}(x)=\left[\frac{\exp(x_i)}{\sum\limits_{k}\exp(x_k)}\right], i=1..n,~x=[x_1, ... , x_n]$$&lt;/div&gt;
&lt;p&gt;Softmax accepts a vector of network's output and converts it to a vector of probability values. For this function we need to use one-hot encoding.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;python
from scipy.special import softmax as s
def softmax(x: Tensor) -&amp;gt; Tensor:
    """Calculate softmax using scipy."""
    return s(x, axis=1)&lt;/code&gt;&lt;/p&gt;
&lt;h3 id="loss-functions"&gt;Loss Functions&lt;/h3&gt;
&lt;p&gt;We implement two loss functions here. We will implement Mean Squared Error Loss class and a Cross Entropy Loss class.&lt;/p&gt;
&lt;h4 id="mean-squared-error-loss"&gt;Mean Squared Error Loss&lt;/h4&gt;
&lt;p&gt;This is a very straight-forward loss function, it takes the output of the last layer of the neural network &lt;span class="math"&gt;\(\hat{y}\)&lt;/span&gt; and ccomputes:&lt;/p&gt;
&lt;div class="math"&gt;$$\mathcal{L}(y, \hat{y}) = \frac{1}{2m}||y-\hat{y}||^2,$$&lt;/div&gt;
&lt;p&gt;where &lt;span class="math"&gt;\(m\)&lt;/span&gt; is the size of &lt;span class="math"&gt;\(y\)&lt;/span&gt; and &lt;/p&gt;
&lt;div class="math"&gt;$$\hat{y}$$&lt;/div&gt;
&lt;p&gt; and &lt;/p&gt;
&lt;div class="math"&gt;$$\vert\vert...\vert\vert$$&lt;/div&gt;
&lt;p&gt; represents the vector norm (sum of squared component-wise differences). The gradient of this function for backpropagation is computed as&lt;/p&gt;
&lt;div class="math"&gt;$$\nabla{\mathcal{L}}=\frac{1}{m}(y-\hat{y})$$&lt;/div&gt;
&lt;h4 id="cross-entropy-loss"&gt;Cross Entropy Loss&lt;/h4&gt;
&lt;p&gt;Cross entropy loss function is defined as follows. Let &lt;span class="math"&gt;\(\hat{y}\)&lt;/span&gt; be the so-called &lt;span class="math"&gt;\({logits}\)&lt;/span&gt;, the outputs of the neural network. Then, we use softmax to calculate the probabilities &lt;span class="math"&gt;\(p=\mathcal{S}\left(\hat{y}\right)\)&lt;/span&gt;. The cross entropy is&lt;/p&gt;
&lt;div class="math"&gt;$$\mathcal{L}(y, \hat{y}) = -\sum\limits_{i} y_i \log p_i,$$&lt;/div&gt;
&lt;p&gt;
where &lt;span class="math"&gt;\(y_i\)&lt;/span&gt; is the true label vector.&lt;/p&gt;
&lt;p&gt;To evaluate the gradient, consider the following argument&lt;/p&gt;
&lt;div class="math"&gt;$$\nabla{\mathcal{L}}(y, \hat{y}) = -\sum\limits_i \frac{\partial \left(y_i \log [\mathcal{S}(x)]_i\right)}{\partial x_j}$$&lt;/div&gt;
&lt;p&gt;
where &lt;span class="math"&gt;\(x\)&lt;/span&gt; is the network's output. Continuing this, we obtain&lt;/p&gt;
&lt;div class="math"&gt;$$\nabla{\mathcal{L}}(y, \hat{y}) = -\sum\limits_i y_i \frac{1}{p_i}\frac{\partial  \mathcal{S}(x)_i}{\partial x_j}$$&lt;/div&gt;
&lt;p&gt;To find the derivative of softmax, consider&lt;/p&gt;
&lt;div class="math"&gt;$$\frac{\partial \mathcal{S}_i}{\partial x_j} = \frac{\partial}{\partial x_j}\left(\frac{\exp(x_i)}{\sum\limits_{k}\exp(x_k)}\right) = \frac{\frac{\partial\exp(x_i)}{\partial x_j} \sum\limits_{k}\exp(x_k) - \exp(x_i) \sum\limits_{k}\frac{\partial\exp(x_k)}{\partial x_j}}{\left(\sum\limits_{k}\exp(x_k)\right)^2},$$&lt;/div&gt;
&lt;div class="math"&gt;$$\frac{\partial \mathcal{S}_i}{\partial x_j} = \frac{\exp(x_i)\delta_{ij} \sum\limits_{k}\exp(x_k) - \exp(x_i)\exp(x_j)}{\left(\sum\limits_{k}\exp(x_k)\right)^2},$$&lt;/div&gt;
&lt;div class="math"&gt;$$\frac{\partial \mathcal{S}_i}{\partial x_j} = \frac{\exp(x_i)}{ \sum\limits_{k}\exp(x_k)}\delta_{ij} - \frac{\exp(x_i)}{\sum\limits_{k}\exp(x_k)}\frac{\exp(x_j)}{\sum\limits_{k}\exp(x_k)} = \mathcal{S}_i\delta_{ij} - \mathcal{S}_i \mathcal{S}_j.$$&lt;/div&gt;
&lt;p&gt;We use &lt;span class="math"&gt;\(\delta_{ij}\)&lt;/span&gt; to represent Kronecker delta-symbol (essentially, identity matrix). Finally, we can interchange the notation &lt;span class="math"&gt;\(\mathcal{S}_i\)&lt;/span&gt; for &lt;span class="math"&gt;\(p_i\)&lt;/span&gt;, since both represent the &lt;span class="math"&gt;\(i\)&lt;/span&gt;th component of the softmax output (the probability)&lt;/p&gt;
&lt;div class="math"&gt;$$\nabla{\mathcal{L}}(y, \hat{y}) = -\sum\limits_i y_i \frac{1}{p_i}p_i(\delta_{ij}-p_j) = - y_j  + p_j\sum\limits_i y_i.$$&lt;/div&gt;
&lt;p&gt;Recall, that the vector &lt;span class="math"&gt;\(y\)&lt;/span&gt; is one-hot encoded, therefore, the sum of its components &lt;span class="math"&gt;\(\sum\limits_i y_i=1\)&lt;/span&gt;. Hence, we obtain&lt;/p&gt;
&lt;div class="math"&gt;$$\nabla{\mathcal{L}}(y, \hat{y}) =p_j - y_j.$$&lt;/div&gt;
&lt;p&gt;```python
class Loss:
    """Placeholder class for losses."""&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;def __init__(self):
    """Initialize the class with 0 gradient."""
    self.grad = 0.

def grad_fn(self, pred: Tensor, true: Tensor) -&amp;gt; Tensor:
    """Create placeholder for the gradient funtion."""
    pass

def loss_fn(self, pred: Tensor, true: Tensor) -&amp;gt; Tensor:
    """Create placeholder for the loss funtion."""
    pass

def __call__(self, pred: Tensor, true: Tensor):
    """Calculate gradient and loss on call."""
    self.grad = self.grad_fn(pred, true)
    return self.loss_fn(pred, true)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;class MSE(Loss):
    """Mean squared error loss."""&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;def __init__(self):
    """Initialize via superclass."""
    super().__init__()

def grad_fn(self, pred: Tensor, true: Tensor) -&amp;gt; Tensor:
    """Calculate the gradient of MSE.

    Args:
        pred: Tensor of predictions (raw output),
        shape (batch, )
        true: Tensor of true labels,
        shape (batch, )

    """
    return (pred - true)/true.shape[0]

def loss_fn(self, pred: Tensor, true: Tensor) -&amp;gt; Tensor:
    """Calculate the MSE.

    Args:
        pred: Tensor of predictions (raw output),
        shape (batch,)
        true: Tensor of true labels (raw output),
        shape (batch,)

    """
    return 0.5*np.sum((pred - true)**2)/true.shape[0]

def __repr__(self):
    """Put pretty representation in Jupyter/IPython."""
    return """Mean Squared Error loss (pred: Tensor, true: Tensor)"""
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;class CrossEntropyLoss(Loss):
    """CrossEntropyLoss class."""&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;def __init__(self) -&amp;gt; None:
    """Initialize via superclass."""
    super().__init__()

def loss_fn(self, logits: Tensor, true: Tensor) -&amp;gt; Tensor:
    """Calculate loss.

    Args:
        logits: Tensor of shape (batch size, number of classes),
        raw output of a neural network

        true: Tensor of shape (batch size,),
        a one-hot encoded vector

    """
    p = softmax(logits)
    return -np.mean(true * np.log(p))

def grad_fn(self, logits: Tensor, true: Tensor) -&amp;gt; Tensor:
    """Calculate the gradient.

    Args:
        logits: Tensor of shape (batch size, number of classes),
        raw output of a neural network

        true: Tensor of shape (batch size, number of classes),
        a one-hot encoded vector

    """
    self.probabilities = softmax(logits)
    return self.probabilities - true
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;```&lt;/p&gt;
&lt;h2 id="building-the-network"&gt;Building the Network&lt;/h2&gt;
&lt;p&gt;Here we describe the main class for our neural network. The main principle is simple, we pass a list of layers and initialize a class &lt;code&gt;Network&lt;/code&gt; with two methods: &lt;code&gt;forward&lt;/code&gt; and &lt;code&gt;backward&lt;/code&gt;. The &lt;code&gt;forward&lt;/code&gt; method performs the forward pass, that is, sends the input data through each layer. The &lt;code&gt;backward&lt;/code&gt; method calls &lt;code&gt;backward&lt;/code&gt; from each layer in the opposite direction (starting with the last layer). It uses the gradient of the lost function as its input.&lt;/p&gt;
&lt;p&gt;```python
from typing import List, Union&lt;/p&gt;
&lt;p&gt;Layer = Union[Linear, ReLU, Sigmoid]&lt;/p&gt;
&lt;p&gt;class Network:
    """Basic Neural Network Class."""&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;def __init__(self, layers: List[Layer]):
    """Initialize the Netowrk with a list of layers."""
    self.layers = layers[:]

def forward(self, x: Tensor):
    """Run the forward pass."""
    for l in self.layers:
        x = l(x)
    return x

def backward(self, grad: Tensor):
    """Run the backward pass."""
    for l in self.layers[::-1]:
        grad = l.backward(grad)
    return grad

def __call__(self, x: Tensor):
    """Run the forward pass on __call__."""
    return self.forward(x)

def __repr__(self) -&amp;gt; str:
    """Print the representation for the network."""
    return "\n".join(l.__repr__() for l in self.layers)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;```&lt;/p&gt;
&lt;h3 id="optimizers"&gt;Optimizers&lt;/h3&gt;
&lt;p&gt;Our main optimizer here is going to be Stochastic Gradient Descent. After we computed the backpropagation, for every layer in the network, we are going to update the weights. If the gradient is &lt;span class="math"&gt;\(\Delta w\)&lt;/span&gt; then the update rule is &lt;/p&gt;
&lt;div class="math"&gt;$$w = w - \eta \Delta w - 2*\alpha w,$$&lt;/div&gt;
&lt;p&gt;where &lt;span class="math"&gt;\(\eta\)&lt;/span&gt; is the learning rate and &lt;span class="math"&gt;\(\alpha\)&lt;/span&gt; is the &lt;span class="math"&gt;\(L^2\)&lt;/span&gt; regularization parameter. The code is presented below.&lt;/p&gt;
&lt;p&gt;```python
class SGD:
    """Stochastic Gradient Descent class."""&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;def __init__(self, lr: float, l2: float = 0.):
    """Initialize with learning rate and l2-regularization parameter."""
    self.lr = lr
    self.l2 = l2

def step(self, net: Network):
    """Perform optimization step."""
    for l in net.layers:
        if hasattr(l, 'dydw'):
            l.W = l.W - self.lr*l.dydw - 2 * self.l2 * l.W
        if hasattr(l, 'dydb'):
            l.b = l.b - self.lr*l.dydb - 2 * self.l2 * l.b
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;```&lt;/p&gt;
&lt;h2 id="training-mnist-in-batches-using-mse"&gt;Training MNIST in Batches using MSE&lt;/h2&gt;
&lt;p&gt;In the code below, we create a training/validation loop. Each important point is commented. &lt;/p&gt;
&lt;p&gt;```python
from tqdm import auto
import numpy as np
import pandas as pd
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split&lt;/p&gt;
&lt;p&gt;def to_one_hot(vector: Tensor) -&amp;gt; Tensor:
    """Create one hot encoding of a vector."""
    oh = np.zeros((vector.shape[0], vector.max()+1))
    oh[np.arange(vector.shape[0]), vector] = 1
    return oh&lt;/p&gt;
&lt;h1 id="load-training-data"&gt;Load training data&lt;/h1&gt;
&lt;p&gt;train = pd.read_csv('mnist_train.csv', header=None).values[:, 1:]
train_label = pd.read_csv(
    'mnist_train.csv', header=None).values[:, 0]&lt;/p&gt;
&lt;h1 id="create-the-basic-network"&gt;Create the basic network&lt;/h1&gt;
&lt;p&gt;net = Network(layers=[
    Linear(784, 128),
    ReLU(),
    Linear(128, 10),
])&lt;/p&gt;
&lt;h1 id="initialize-loss-class"&gt;Initialize loss class&lt;/h1&gt;
&lt;p&gt;loss = MSE()&lt;/p&gt;
&lt;h1 id="initialize-the-optimizer-learning-rate-is-00001"&gt;Initialize the optimizer, learning rate is 0.0001&lt;/h1&gt;
&lt;p&gt;optim = SGD(1e-4)&lt;/p&gt;
&lt;h1 id="permform-the-trainval-split"&gt;permform the train/val split&lt;/h1&gt;
&lt;p&gt;x_train, x_val, y_train, y_val = train_test_split(
    train.astype(np.float32) / 255,
    train_label.astype(np.int32),
    test_size=0.2, random_state=42)  # to_one_hot&lt;/p&gt;
&lt;h1 id="convert-labels-to-one-hot-encodings"&gt;Convert labels to one-hot encodings&lt;/h1&gt;
&lt;p&gt;y_train = to_one_hot(y_train)
y_val = to_one_hot(y_val)&lt;/p&gt;
&lt;h1 id="batch-size"&gt;batch size&lt;/h1&gt;
&lt;p&gt;batch_size = 100&lt;/p&gt;
&lt;h1 id="progress-bar-may-not-be-visible-in-pdf-mode-but-it-works-in-notebook-or-terminal-mode"&gt;progress bar may not be visible in PDF mode, but it works in notebook or terminal mode&lt;/h1&gt;
&lt;h1 id="we-set-it-to-100-epochs-here"&gt;we set it to 100 epochs here&lt;/h1&gt;
&lt;p&gt;progress_bar = auto.tqdm(range(100))
for epoch in progress_bar:
    # offset to iterate through batches
    offset = 0
    # initialize errors for validation and training
    val_err = 0
    err = 0
    while (offset+batch_size &amp;lt;= len(x_train)):
        # while we can move through batches, extract them
        data = x_train[offset:offset+batch_size, :]
        label = y_train[offset:offset+batch_size]
        # make prediction
        pred = net(data)
        # calculate loss (and average error)
        err += loss(pred, label)/(len(x_train)/batch_size)
        # begin backprop
        g = net.backward(loss.grad)
        # perform SGD step
        optim.step(net)
        # move to next batch
        offset += batch_size
    # reset offset for validation
    offset = 0
    while (offset+batch_size &amp;lt;= len(x_val)):
        # get validation data while we are not at the end
        val_data = x_val[offset:offset+batch_size, :]
        val_label = y_val[offset:offset+batch_size]
        # make prediction
        pred = net(val_data)
        # get loss and error
        val_err += loss(pred, val_label)/(len(x_val)/batch_size)
        # move offset to next batch
        offset += batch_size
        if (epoch) % 2 == 0:
            # update progress bar info
            progress_bar.set_postfix({"Mean_loss_train": err,
                                      "Mean_loss_val": val_err})
```&lt;/p&gt;
&lt;p&gt;```python&lt;/p&gt;
&lt;h1 id="load-test-data-and-convert-to-one-hot"&gt;Load test data and convert to one-hot&lt;/h1&gt;
&lt;p&gt;test = pd.read_csv('mnist_test.csv', header=None).values[:, 1:]
test_label = pd.read_csv('mnist_test.csv', header=None).values[:, 0]
test_label = to_one_hot(test_label)&lt;/p&gt;
&lt;h1 id="place-offset-and-initialize-error-to-0"&gt;place offset and initialize error to 0&lt;/h1&gt;
&lt;p&gt;offset = 0
test_err = 0.
while (offset+batch_size &amp;lt;= len(test)):
    # get data batch
    data = test[offset:offset+batch_size, :]
    label = test_label[offset:offset+batch_size]
    # make prediction
    pred = net(data)
    # get error
    test_err += loss(pred, label)/(len(test)/batch_size)
    offset += batch_size&lt;/p&gt;
&lt;p&gt;print(f"Test Error is {test_err:.2f} ...")
```&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Test Error is 2643.26 ...
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;```python
from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt
from IPython.display import set_matplotlib_formats
set_matplotlib_formats('retina')
plt.style.use('ggplot')
%matplotlib inline&lt;/p&gt;
&lt;p&gt;y_true = test_label.argmax(1)
y_pred = net(test).argmax(1)
ax = plt.figure(figsize=(15, 7))
ax = sns.heatmap(confusion_matrix(y_true, y_pred), annot=True, fmt=".3f")
ax.set_xlabel("True")
ax.set_ylabel("Predicted")
```&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Text(114.0, 0.5, 'Predicted')
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img alt="png" src="https://iliailmer.github.io/images/2020-06-14-numpy-learn/output_17_1.png" /&gt;&lt;/p&gt;
&lt;p&gt;We can see from the confusion matrix above that the model performs poorly if the training is based on MSE. Let us try a different loss function: Cross Entropy loss.&lt;/p&gt;
&lt;h2 id="cross-entropy-training"&gt;Cross Entropy Training&lt;/h2&gt;
&lt;p&gt;```python
"""Training example for a simple network with MNIST Dataset."""
from tqdm import auto
import numpy as np
import pandas as pd
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split
from datatype import Tensor&lt;/p&gt;
&lt;p&gt;def to_one_hot(vector: Tensor) -&amp;gt; Tensor:
    """Create one hot encoding of a vector."""
    oh = np.zeros((vector.shape[0], vector.max()+1))
    oh[np.arange(vector.shape[0]), vector] = 1
    return oh&lt;/p&gt;
&lt;h1 id="load-training-data_1"&gt;Load training data&lt;/h1&gt;
&lt;p&gt;train = pd.read_csv('mnist_train.csv', header=None).values[:, 1:]
train_label = pd.read_csv(
    'mnist_train.csv', header=None).values[:, 0]&lt;/p&gt;
&lt;h1 id="create-the-network"&gt;Create the network&lt;/h1&gt;
&lt;p&gt;net = Network(layers=[
    Linear(784, 128),
    Sigmoid(),
    Linear(128, 10),
])&lt;/p&gt;
&lt;h1 id="initialize-loss-class_1"&gt;Initialize loss class&lt;/h1&gt;
&lt;p&gt;loss = CrossEntropyLoss()&lt;/p&gt;
&lt;h1 id="initialize-optimizer-with-regularization"&gt;Initialize optimizer with regularization&lt;/h1&gt;
&lt;p&gt;optim = SGD(5e-2, 0.0001)&lt;/p&gt;
&lt;h1 id="split"&gt;split&lt;/h1&gt;
&lt;p&gt;x_train, x_val, y_train, y_val = train_test_split(
    train.astype(np.float32) / 255,
    train_label.astype(np.int32),
    test_size=0.2, random_state=42)  # to_one_hot&lt;/p&gt;
&lt;h1 id="to-one-hot"&gt;to one-hot&lt;/h1&gt;
&lt;p&gt;y_train = to_one_hot(y_train)
y_val = to_one_hot(y_val)
batch_size = 100
progress_bar = auto.tqdm(range(200))&lt;/p&gt;
&lt;h1 id="this-will-be-used-later"&gt;this will be used later&lt;/h1&gt;
&lt;p&gt;accuracies: dict = {"train": [],
                    "val": [],
                    "test": []}
acc_train: list = []
acc_val: list = []&lt;/p&gt;
&lt;p&gt;for epoch in progress_bar:
    offset = 0
    val_err = 0
    err = 0
    while (offset+batch_size &amp;lt;= len(x_train)):
        # grab the batch
        data = x_train[offset:offset+batch_size, :]
        label = y_train[offset:offset+batch_size, :]
        # I try to avoid a runtime warning (only happens in notebook, not sure why)
        try:
            pred = net(data)
        except RuntimeWarning:
            print(f"Runtime warning on {offset}")
        # get loss
        err += loss(pred, label)/(len(x_train)/batch_size)
        # backprop
        g = net.backward(loss.grad)
        # update weights
        optim.step(net)
        # next batch index
        offset += batch_size
        # keep scores
        acc_train.append(accuracy_score(
            label.argmax(axis=1),
            pred.argmax(axis=1)
        ))
    offset = 0
    while (offset+batch_size &amp;lt;= len(x_val)):
        # get validation data
        val_data = x_val[offset:offset+batch_size, :]
        val_label = y_val[offset:offset+batch_size]
        # predict
        pred = net(val_data)
        # get loss
        val_err += loss(pred, val_label)/(len(x_val)/batch_size)
        # next batch index
        offset += batch_size
        # keep scores
        acc_val.append(accuracy_score(
            val_label.argmax(axis=1),
            pred.argmax(axis=1)
        ))
    if (epoch) % 2 == 0:
        # update progress bar
        progress_bar.set_postfix({"loss_train": err,
                                  "loss_val": val_err,
                                  "acc_val": np.mean(acc_val)})
    # keep scores for visualization
    accuracies['train'].append(np.mean(acc_train))
    accuracies['val'].append(np.mean(acc_val))
    acc_train = []
    acc_val = []&lt;/p&gt;
&lt;h1 id="load-test-data-and-convert-to-one-hot_1"&gt;Load test data and convert to one-hot&lt;/h1&gt;
&lt;p&gt;test = pd.read_csv('mnist_test.csv', header=None).values[:, 1:]
test_label = to_one_hot(pd.read_csv(
    'mnist_test.csv',
    header=None).values[:, 0])&lt;/p&gt;
&lt;p&gt;offset = 0
test_err = 0.
while (offset+batch_size &amp;lt;= len(test)):
    # get batch
    data = test[offset:offset+batch_size, :]
    label = test_label[offset:offset+batch_size]
    # predict
    pred = net(data)
    # get loss
    test_err += loss(pred, label)/(len(test)/batch_size)
    # offset
    offset += batch_size
    # get scores
    accuracies['test'].append(accuracy_score(
        label.argmax(axis=1),
        pred.argmax(axis=1)
    ))&lt;/p&gt;
&lt;p&gt;print(f"Average Test Accuracy: {np.mean(accuracies['test']):.2f}")&lt;/p&gt;
&lt;p&gt;```&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Average Test Accuracy: 0.95
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let us plot the evolution of accuracies during testing and confusion matrix. For a higher performing model we expect to see the confusion matrix consolidate results on the diagonal:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;python
fig = plt.figure(figsize=(15, 6))
_ = plt.plot(accuracies['train'], label="Training score")
_ = plt.plot(accuracies['val'], label="Validation score")
_ = plt.xlabel("Epoch")
_ = plt.ylabel("Accuracy")
_ = plt.title("Accuracy per epoch")
_ = plt.legend()&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="png" src="https://iliailmer.github.io/images/2020-06-14-numpy-learn/output_22_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;```python
y_true = test_label.argmax(1)
y_pred = net(test).argmax(1)
_ = plt.figure(figsize=(15, 7))
ax = sns.heatmap(confusion_matrix(y_true, y_pred), annot=True, fmt=".3f")&lt;/p&gt;
&lt;p&gt;&lt;em&gt;=ax.set_xlabel("True")
&lt;/em&gt;=ax.set_ylabel("Predicted")
```&lt;/p&gt;
&lt;p&gt;&lt;img alt="png" src="https://iliailmer.github.io/images/2020-06-14-numpy-learn/output_23_1.png" /&gt;&lt;/p&gt;
&lt;h2 id="conclusion"&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;We implemented a neural network class that supports several activation functions. We followed here a design pattern based on PyTorch deep learning package. We implemented linear (fully-connected) layer, ReLU and Sigmoid layer. Each layer includes a backpropagation function &lt;code&gt;backward&lt;/code&gt; that sends the gradient from the output back to input. As a result we were able to use a Cross Entropy Loss function to train a handwritten digit classifier with 95% accuracy on the test set. Notice that on the graph we observe a pattern of periodically dropping accuracy. I assume this is due to internal structure of the loss landscape: we repeatedly "walk" out of the minimum region and then "walk" back in during the SGD.&lt;/p&gt;
&lt;p&gt;Using the Mean Squared Error loss function did not yield a productive result here, however, while developing this library, I observed that if I train on a small sample of data (i.e. 50 items or less), the model was able to learn the underlying data representations very well and was able to over fit. This is one the tests usually performed on new architectures in order to check if the model can learn at all. This, unfortunately, did not scale in case of MSE but it did for Cross Entropy Loss.&lt;/p&gt;
&lt;p&gt;The overall structure of the project is posted on my github &lt;a href="https://github.com/iliailmer/numpy_learn"&gt;page&lt;/a&gt;&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="Posts"></category><category term="machine learning"></category><category term="python"></category><category term="numpy"></category><category term="deep learning"></category></entry><entry><title>Three Ways to Deal With Imbalance</title><link href="https://iliailmer.github.io/2020/03/precision-recall.html" rel="alternate"></link><published>2020-03-02T00:00:00-05:00</published><updated>2020-03-02T00:00:00-05:00</updated><author><name>Ilia Ilmer</name></author><id>tag:iliailmer.github.io,2020-03-02:/2020/03/precision-recall.html</id><summary type="html">&lt;p&gt;In this post, I put together an interesting example of what to do with imbalanced datasets and why precision and recall matter.&lt;/p&gt;
&lt;h2 id="introduction"&gt;Introduction&lt;/h2&gt;
&lt;p&gt;The following is part of a Machine learning assignment I had to do while at CUNY. This particular example illustrates quite well the importance of understanding various …&lt;/p&gt;</summary><content type="html">&lt;p&gt;In this post, I put together an interesting example of what to do with imbalanced datasets and why precision and recall matter.&lt;/p&gt;
&lt;h2 id="introduction"&gt;Introduction&lt;/h2&gt;
&lt;p&gt;The following is part of a Machine learning assignment I had to do while at CUNY. This particular example illustrates quite well the importance of understanding various measures of model quality such as accuracy, precision, recall, etc.&lt;/p&gt;
&lt;p&gt;The idea is to predict whether a client will have a credit card default given some simple data. An insult to injury is a heavily imbalanced dataset: 97% of examples are "Yes"-labeled, making it difficult to train a good classifier.&lt;/p&gt;
&lt;!-- 1. **Stratified sampling**. Split the `default` dataset into `df_train` (60%), `df_validation`(20%), and `df_test` (20%) so that all sets have the same percentage of positive cases. 
2. **Augment data with oversampling.** Increase the amount of positive cases by adding duplicates randomly sampled from the positive class. Create a new data frame `df_train_over` where the number of positive cases is equal to the number of negative cases. 
3. **Augment data with undersampling**. Randomly remove samples from the negative class. Create a new data frame `df_train_under` where the number of negative cases is equal to the number of positive cases. 
4. Train a logistic regression model on each of the three training sets: `df_train`, `df_train_over`, `df_train_under`. 
5. For each model, compute the **confusion matrix**, **precision score**, and **recall score** on `df_validation. Decide which model has the best performance and explain why.  Please read this article to learn the definitions.
6. Apply the best model to `df_test` and compute the **confusion matrix**, **precision score**, and **recall score**. Are the results similar to those from `df_validation`? --&gt;

&lt;p&gt;We will dive into the solution, but first, some imports:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;python
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
%matplotlib inline
import numpy as np
import gc
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, precision_score, recall_score
from sklearn.linear_model import LogisticRegressionCV, LogisticRegression
plt.style.use('fivethirtyeight')&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;A plotting helper:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;py
def plot_cm(y_pred, y_true):
    """Plot confusion matrix based on
       true vs. predicted values."""
    cm = confusion_matrix(y_true=y_true, y_pred=y_pred)
    prec = precision_score(y_true=y_true, y_pred=y_pred)
    rec = recall_score(y_true=y_true, y_pred=y_pred)
    sns.heatmap(cm, annot=True)
    plt.title(f"Precision: {prec:.2f}, Recall: {rec:.2f}")&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Finally, reading the &lt;a href="https://github.com/JWarmenhoven/ISLR-python/blob/master/Notebooks/Data/Default.xlsx?raw=true"&gt;data&lt;/a&gt;:&lt;/p&gt;
&lt;p&gt;```python
df = pd.read_excel("Default.xlsx", header=0).iloc[:, 1:]&lt;/p&gt;
&lt;h1 id="convert-strings-to-binary-int32-01-values"&gt;convert strings to binary int32 0,1 values&lt;/h1&gt;
&lt;p&gt;df['default'] = df['default'].apply(lambda x: 0 if x == 'No' else 1).astype(
    np.int32)
df['student'] = df['student'].apply(lambda x: 0 if x == 'No' else 1).astype(
    np.int32)
X = df.drop(['default'], axis=1)
y = df['default']
```&lt;/p&gt;
&lt;p&gt;To save memory: convert applicable columns from float64(double) to float32(float). This may help with much bigger datasets, this one is relatively small, though. Applicable here means max value of a column falls within the limits of the float32 range:&lt;/p&gt;
&lt;p&gt;```py
for column in df.columns:
    if df[column].values.max() &amp;lt; np.finfo(np.float32).max:
        if df[column].values.min() &amp;gt; np.finfo(np.float32).min:
            df[column] = df[column].values.astype(np.float32)&lt;/p&gt;
&lt;h1 id="garbage-collector"&gt;garbage collector&lt;/h1&gt;
&lt;p&gt;gc.collect()
```&lt;/p&gt;
&lt;p&gt;Let's look at the distribution of the target value:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;python
ax = sns.countplot(data=df, x='default')&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="png" src="https://iliailmer.github.io/images/2020-03-02-precision-recall/output_5_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;The histogram above verifies the problem: the data is highly imbalanced. To train a linear regression classifier, we will try to remedy the issue with three approaches:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;We sample a training, validation, and testing subsets in a &lt;strong&gt;&lt;em&gt;stratified&lt;/em&gt;&lt;/strong&gt; manner, that is, preserving the ratio between "0" and "1" labels.&lt;/li&gt;
&lt;li&gt;We will &lt;strong&gt;&lt;em&gt;oversample&lt;/em&gt;&lt;/strong&gt; the less represented class: "1", or "Yes"-labeled default examples.&lt;/li&gt;
&lt;li&gt;We will &lt;strong&gt;&lt;em&gt;undersample&lt;/em&gt;&lt;/strong&gt; the overrepresented class: "0".&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id="stratified-sampling"&gt;Stratified Sampling&lt;/h2&gt;
&lt;p&gt;To sample in a way that the imbalance is preserved (stratified) we will pass an argument &lt;code&gt;stratify&lt;/code&gt; to the &lt;code&gt;train_test_split&lt;/code&gt; function from &lt;code&gt;sklearn&lt;/code&gt;. Specifically, we will pass the column of labels &lt;code&gt;df['default']&lt;/code&gt; so that the function determines the exact distribution.&lt;/p&gt;
&lt;p&gt;```python
df_train, df_test, y_train, y_test = train_test_split(X,
                                                      y,
                                                      random_state=42,
                                                      stratify=df['default'],
                                                      train_size=0.6)&lt;/p&gt;
&lt;p&gt;df_val, df_test, y_val, y_test = train_test_split(df_test,
                                                  y_test,
                                                  random_state=42,
                                                  stratify=y_test,
                                                  train_size=0.5)
```&lt;/p&gt;
&lt;p&gt;The plot below will illustrate the distribution of labels in the sampled data.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;python
fig, ax = plt.subplots(ncols=3, figsize=(12, 4))
fig.suptitle("Left to right: train, val, test label counts.")
for i, data in zip(range(3), (y_train, y_val, y_test)):
    sns.countplot(x=data, ax=ax[i])&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="png" src="https://iliailmer.github.io/images/2020-03-02-precision-recall/output_11_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;```python
print(f'Train data to original dataset: {len(df_train)/len(X) * 100}%')
print(f'Validation data to original dataset: {len(df_val)/len(X) * 100}%')
print(f'Test data to original dataset: {len(df_test)/len(X) * 100}%')&lt;/p&gt;
&lt;p&gt;print(f'\nNegative labels in original data: {len(X[y==0])/len(X) * 100 :.3}%')
print(f'Negative labels in train data: {(len(df_train[y_train==0])/len(df_train) * 100) :.3}%')
print(f'Negative labels in validation data: {(len(df_val[y_val==0])/len(df_val) * 100) :.3}%')
print(f'Negative labels in test data: {(len(df_test[y_test==0])/len(df_test) * 100) :.3}%')&lt;/p&gt;
&lt;p&gt;```&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Train data to original dataset: 60.0%
Validation data to original dataset: 20.0%
Test data to original dataset: 20.0%

Negative labels in original data: 96.7%
Negative labels in train data: 96.7%
Negative labels in validation data: 96.7%
Negative labels in test data: 96.7%
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id="oversampling"&gt;Oversampling&lt;/h2&gt;
&lt;p&gt;For oversampling we will use a package called &lt;code&gt;imbalanced-learn&lt;/code&gt; available &lt;a href="https://pypi.org/project/imbalanced-learn/"&gt;from PyPI&lt;/a&gt;. It has built-in classes for various over- and under-sampling methods. We will use basic &lt;code&gt;RandomOverSampler&lt;/code&gt; and &lt;code&gt;RandomUnderSampler&lt;/code&gt; classes.&lt;/p&gt;
&lt;p&gt;The package is built with similarities to other &lt;code&gt;sklearn&lt;/code&gt; conventions, so calling &lt;code&gt;fit&lt;/code&gt; methods will give us the necessary results.&lt;/p&gt;
&lt;p&gt;```python
from imblearn.over_sampling import RandomOverSampler&lt;/p&gt;
&lt;p&gt;ros = RandomOverSampler(random_state=42)  # initialize
df_train_over, y_train_over = ros.fit_sample(
    df_train, y=y_train)  # resample training data
ax = sns.countplot(x=y_train_over)  # plot value counts for the labels
t = plt.suptitle("Oversampled value counts.")
```&lt;/p&gt;
&lt;p&gt;&lt;img alt="png" src="https://iliailmer.github.io/images/2020-03-02-precision-recall/output_15_0.png" /&gt;&lt;/p&gt;
&lt;h2 id="underspamling"&gt;Underspamling&lt;/h2&gt;
&lt;p&gt;```python
from imblearn.under_sampling import RandomUnderSampler&lt;/p&gt;
&lt;p&gt;rus = RandomUnderSampler(random_state=42, )  # initialize
df_train_under, y_train_under = rus.fit_sample(df_train, y=y_train)  # resample
ax = sns.countplot(x=y_train_under)  # plot
t = plt.suptitle("Undersampled value counts.")
```&lt;/p&gt;
&lt;p&gt;&lt;img alt="png" src="https://iliailmer.github.io/images/2020-03-02-precision-recall/output_17_0.png" /&gt;&lt;/p&gt;
&lt;h2 id="train-naively-without-stratification"&gt;Train naively without stratification&lt;/h2&gt;
&lt;p&gt;Let us first train logistic regression model on a similarly split data without stratification.&lt;/p&gt;
&lt;p&gt;```python
df_train_naive, df_test_naive, y_train_naive, y_test_naive = train_test_split(
    X, y, random_state=42, train_size=0.6)&lt;/p&gt;
&lt;p&gt;df_val_naive, df_test_naive, y_val_naive, y_test_naive = train_test_split(
    df_test_naive, y_test_naive, random_state=42, train_size=0.6)
```&lt;/p&gt;
&lt;p&gt;```python
logreg = LogisticRegression(penalty='none', max_iter=1e4, random_state=42)
logreg.fit(df_train_naive, y_train_naive)
y_pred = logreg.predict(df_val_naive)&lt;/p&gt;
&lt;p&gt;plot_cm(y_val_naive, y_pred)
```&lt;/p&gt;
&lt;p&gt;&lt;img alt="png" src="https://iliailmer.github.io/images/2020-03-02-precision-recall/output_21_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;We observe zero precision and zero recall scores and the model overfits on the '0' class, which is expected and is bad.&lt;/p&gt;
&lt;h2 id="train-on-stratified"&gt;Train on Stratified&lt;/h2&gt;
&lt;p&gt;Below we train on the stratified data. We observe a better recall and precision scores and the predicted result on validation data follows the distribution of labels as in the training data (note that this heuristic is absolutely non-strict and does not necessarily indicate whether a model is good or bad).&lt;/p&gt;
&lt;p&gt;```python
logreg = LogisticRegression(penalty='none', max_iter=1e4, random_state=42)
logreg.fit(df_train, y_train)
y_pred = logreg.predict(df_val)&lt;/p&gt;
&lt;p&gt;plot_cm(y_val, y_pred)
```&lt;/p&gt;
&lt;p&gt;&lt;img alt="png" src="https://iliailmer.github.io/images/2020-03-02-precision-recall/output_25_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;python
ax = plt.subplot()
ax = sns.countplot(y_pred, ax=ax)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="png" src="https://iliailmer.github.io/images/2020-03-02-precision-recall/output_26_0.png" /&gt;&lt;/p&gt;
&lt;h2 id="train-on-oversampled"&gt;Train on Oversampled&lt;/h2&gt;
&lt;p&gt;When training on Oversampled data we get a very high precision score but lose the recall score.&lt;/p&gt;
&lt;p&gt;```python
logreg = LogisticRegression(penalty='none', max_iter=1e4, random_state=42)
logreg.fit(df_train_over, y_train_over)
y_pred = logreg.predict(df_val)&lt;/p&gt;
&lt;p&gt;plot_cm(y_val, y_pred)
```&lt;/p&gt;
&lt;p&gt;&lt;img alt="png" src="https://iliailmer.github.io/images/2020-03-02-precision-recall/output_29_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;```python
y_pred = logreg.predict(df_test)&lt;/p&gt;
&lt;p&gt;plot_cm(y_test, y_pred)
```&lt;/p&gt;
&lt;p&gt;&lt;img alt="png" src="https://iliailmer.github.io/images/2020-03-02-precision-recall/output_30_0.png" /&gt;&lt;/p&gt;
&lt;h2 id="train-on-undersampled"&gt;Train on Undersampled&lt;/h2&gt;
&lt;p&gt;A similar behavior occurs in the undersampled case, we see increase in Precision compared to naive and stratified cases, but both precision and recall are a bit lower that oversampled case.&lt;/p&gt;
&lt;p&gt;```python
logreg = LogisticRegression(penalty='none', max_iter=1e4, random_state=42)
logreg.fit(df_train_under, y_train_under)
y_pred = logreg.predict(df_val)&lt;/p&gt;
&lt;p&gt;plot_cm(y_val, y_pred)
```&lt;/p&gt;
&lt;p&gt;&lt;img alt="png" src="https://iliailmer.github.io/images/2020-03-02-precision-recall/output_33_0.png" /&gt;&lt;/p&gt;
&lt;h2 id="conclusion"&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;In this assignment, we considered a problem of default prediction for a credit card holder. We omitted most of preliminary data analysis and instead focused on basic model building for a highly imbalanced dataset. The proportion of negative labels is 97% out of all given data. Let us briefly outline meaning behind precision and recall scores.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Precision score&lt;/strong&gt; shows the ratio of true positive predictions over all positive predictions regardless if they were true or false. If the number of true positive predictions is negligible compared to false positives then precision is low.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Recall score&lt;/strong&gt;, on the other hand, shows the ratio of true positives versus the sum of true positive and false negative predictions. That is, if the prediction's number of true positive cases is trumped by the number of false negative cases, the recall score will be higher.&lt;/p&gt;
&lt;p&gt;Card default is essentially the inability to pay off the card's balance. In this case, we are not willing to accept a false negative prediction: if we forecast that the default does not happen and in reality it does then we (the bank) are in the losing position. On the other hand, the false positive case does not affect us because in the worst case the cardholder pays off their debt and the default does not happen.&lt;/p&gt;
&lt;p&gt;Since we want to be as effective as possible in our prediction, we must recommend a model with a higher recall score, which in this case is a stratified logistic recall score model.&lt;/p&gt;
&lt;p&gt;```python
logreg = LogisticRegression(penalty='none', max_iter=1e4, random_state=42)
logreg.fit(df_train, y_train)
y_pred = logreg.predict(df_val)&lt;/p&gt;
&lt;p&gt;plot_cm(y_val, y_pred)
```&lt;/p&gt;
&lt;p&gt;&lt;img alt="png" src="https://iliailmer.github.io/images/2020-03-02-precision-recall/output_36_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;```python
y_pred = logreg.predict(df_test)&lt;/p&gt;
&lt;p&gt;plot_cm(y_test, y_pred)
```&lt;/p&gt;
&lt;p&gt;&lt;img alt="png" src="https://iliailmer.github.io/images/2020-03-02-precision-recall/output_37_0.png" /&gt;&lt;/p&gt;</content><category term="Posts"></category><category term="machine learning"></category><category term="logistic regression"></category><category term="python"></category><category term="scikit-learn"></category><category term="statistical learning"></category></entry><entry><title>Linear Regression as the Simplest Classifier</title><link href="https://iliailmer.github.io/2020/02/data-explore.html" rel="alternate"></link><published>2020-02-24T00:00:00-05:00</published><updated>2020-02-24T00:00:00-05:00</updated><author><name>Ilia Ilmer</name></author><id>tag:iliailmer.github.io,2020-02-24:/2020/02/data-explore.html</id><summary type="html">&lt;p&gt;In this post I wanted to describe a simple application of a linear least squares method to a problem of data classification. It is a naive approach and is unlikely to beat more sophisticated techniques like &lt;a href="https://en.wikipedia.org/wiki/Logistic_regression"&gt;Logistic Regression&lt;/a&gt;, for instance.&lt;/p&gt;
&lt;h3 id="imports"&gt;Imports&lt;/h3&gt;
&lt;p&gt;Some imports we are going to need for this …&lt;/p&gt;</summary><content type="html">&lt;p&gt;In this post I wanted to describe a simple application of a linear least squares method to a problem of data classification. It is a naive approach and is unlikely to beat more sophisticated techniques like &lt;a href="https://en.wikipedia.org/wiki/Logistic_regression"&gt;Logistic Regression&lt;/a&gt;, for instance.&lt;/p&gt;
&lt;h3 id="imports"&gt;Imports&lt;/h3&gt;
&lt;p&gt;Some imports we are going to need for this piece.&lt;/p&gt;
&lt;p&gt;```python
import numpy as np
import pandas as pd
from sklearn.linear_model import LinearRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt
%matplotlib inline&lt;/p&gt;
&lt;p&gt;plt.style.use("ggplot")
```&lt;/p&gt;
&lt;h3 id="prepare-the-data"&gt;Prepare the data&lt;/h3&gt;
&lt;p&gt;Data can be found &lt;a href="https://web.stanford.edu/~hastie/ElemStatLearn/"&gt;here&lt;/a&gt;. The link also has information about the textbook with excellent theoretical background on much of Machine Learning (and Computational Statistics).&lt;/p&gt;
&lt;p&gt;The data is a collection of hand-written digits. Each row of the data represents pixels of the image. For simplicity, we discard all labels except 2 and 3 making the problem a binary classification one (since only two labels are involved).&lt;/p&gt;
&lt;p&gt;We load files with space character as a separator and no header&lt;/p&gt;
&lt;p&gt;&lt;code&gt;python
train = pd.read_csv('zip.train', sep=' ', header=None).drop(257, axis=1)
test = pd.read_csv('zip.test', sep=' ', header=None)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Select only required labels: (by default labels are read as &lt;code&gt;float64&lt;/code&gt; but we won't worry about that) &lt;/p&gt;
&lt;p&gt;&lt;code&gt;python
train = train.loc[train[0].isin([2.0, 3.0])].reset_index(drop=True)
test = test.loc[test[0].isin([2.0, 3.0])].reset_index(drop=True)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;```python&lt;/p&gt;
&lt;h1 id="convert-types-to-int32-and-replace-labels-with-0-and-1"&gt;convert types to int32 and replace labels with 0 and 1&lt;/h1&gt;
&lt;p&gt;train[0] = train[0].astype(np.int32).map({2: 0, 3: 1})
test[0] = test[0].astype(np.int32).map({2: 0, 3: 1})&lt;/p&gt;
&lt;p&gt;X, y = train.iloc[:, 1:], train.iloc[:, 0]
X_test, y_test = test.iloc[:, 1:], test.iloc[:, 0]
```&lt;/p&gt;
&lt;p&gt;&lt;code&gt;python
X.info()&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;class 'pandas.core.frame.DataFrame'&amp;gt;
RangeIndex: 1389 entries, 0 to 1388
Columns: 256 entries, 1 to 256
dtypes: float64(256)
memory usage: 2.7 MB
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;python
y.describe()&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;count    1389.000000
mean        0.473722
std         0.499489
min         0.000000
25%         0.000000
50%         0.000000
75%         1.000000
max         1.000000
Name: 0, dtype: float64
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;python
X_test.info()&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;class 'pandas.core.frame.DataFrame'&amp;gt;
RangeIndex: 364 entries, 0 to 363
Columns: 256 entries, 1 to 256
dtypes: float64(256)
memory usage: 728.1 KB
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;python
y_test.describe()&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;count    364.000000
mean       0.456044
std        0.498750
min        0.000000
25%        0.000000
50%        0.000000
75%        1.000000
max        1.000000
Name: 0, dtype: float64
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id="some-helper-functions"&gt;Some helper functions&lt;/h4&gt;
&lt;p&gt;```python
def show_sample(data: pd.DataFrame):
    """Show 4 images from the dataset (random)."""
    sample = data.sample(4)
    fig, ax = plt.subplots(2, 2, figsize=(10, 8))
    for i in range(2):
        for j in range(2):
            ax[i, j].imshow(sample.iloc[2 * i + j, 1:].values.reshape(16, 16))
            ax[i, j].axis('off')
            ax[i, j].set_title(f'Label: {sample.iloc[2*i+j, 0]}')
    plt.show()&lt;/p&gt;
&lt;p&gt;def raw2label(y_pred, threshold=0):
    """Convert raw label into a int label with a threshold."""
    return np.int32(y_pred &amp;gt; threshold)
```&lt;/p&gt;
&lt;p&gt;&lt;code&gt;python
show_sample(test)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="png" src="https://iliailmer.github.io/images/2020-02-24-data-explore/output_18_0.png" /&gt;&lt;/p&gt;
&lt;h3 id="linear-regression-fitting"&gt;Linear Regression fitting&lt;/h3&gt;
&lt;p&gt;We will approach the solution in the following way. Firstly, we will train a linear regression model on the available data (256 pixel intensity values). Note that the problem is high-dimensional and therefore it is impossible to visualize all of it at once.&lt;/p&gt;
&lt;p&gt;However, the main idea of the linear regression based classifier remains simple: we find a hyperplane in the &lt;span class="math"&gt;\(p+1=257\)&lt;/span&gt; dimensional space that fits the training data perfectly:&lt;/p&gt;
&lt;div class="math"&gt;$$ \hat{y}=\mathbf{X}\hat{\beta},$$&lt;/div&gt;
&lt;p&gt;where &lt;span class="math"&gt;\(X_i\)&lt;/span&gt; is the input column vector (features) with intercept (that is &lt;span class="math"&gt;\(X_0=1\)&lt;/span&gt;):&lt;/p&gt;
&lt;div class="math"&gt;$$\\X_i=(1, X_{i1} ,\dots X_{ip} )^T \in \mathbb{R}^{p+1},$$&lt;/div&gt;
&lt;p&gt;&lt;span class="math"&gt;\(\mathbf{X}\)&lt;/span&gt; is the matrix of features&lt;/p&gt;
&lt;div class="math"&gt;$$\\\mathbf{X} = [X_1^T,\dots, X_n^T]\in \mathbb{R}^{n\times(p+1)}\text{},$$&lt;/div&gt;
&lt;p&gt;and &lt;span class="math"&gt;\(\beta=[\beta_0, \dots, \beta_p]\)&lt;/span&gt; is the vector of parameters&lt;/p&gt;
&lt;div class="math"&gt;$$\\\beta=[\beta_0, \dots, \beta_p]\in \mathbb{R}^{p+1},$$&lt;/div&gt;
&lt;p&gt;where &lt;span class="math"&gt;\(\hat{\beta}\)&lt;/span&gt; is given by &lt;/p&gt;
&lt;div class="math"&gt;$$ \hat{\beta} = (X^TX)^{-1}X^Ty.$$&lt;/div&gt;
&lt;p&gt;We are projecting our training set &lt;span class="math"&gt;\(\mathbf{X}\)&lt;/span&gt; orthogonally onto the hyperplane defined by &lt;span class="math"&gt;\(\hat\beta\)&lt;/span&gt;. We can then derive a classifier from there as follows: let us set up the threshold &lt;span class="math"&gt;\(t\)&lt;/span&gt; such that if for a given unseen feature vector &lt;span class="math"&gt;\(X_{test}\)&lt;/span&gt; the value &lt;span class="math"&gt;\(y_{test}=X_{test}^T\hat\beta=\hat\beta_0+\sum\limits_{i=1}^p (X_{test})_i\hat\beta_i\)&lt;/span&gt; is greater than &lt;span class="math"&gt;\(t\)&lt;/span&gt;, we assign label 1, otherwise 0.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;python
linreg = LinearRegression()
linreg.fit(X, y)&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id="train-set-predictions"&gt;Train set predictions&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;python
y_true = y.copy().values
y_pred = linreg.predict(X)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;We select the threshold range between the minimum and maximum value of the predicted &lt;span class="math"&gt;\(y\)&lt;/span&gt; with a step 0.1 and then check the accuracy for each threshold.&lt;/p&gt;
&lt;p&gt;```python
thresh_range = np.arange(y_pred.min(), y_pred.max(), 0.1)
train_acc_scores = []&lt;/p&gt;
&lt;p&gt;for t in thresh_range:
    train_acc_scores.append(
        accuracy_score(y_pred=raw2label(y_pred, t), y_true=y_true))
```&lt;/p&gt;
&lt;p&gt;```python
fig, ax = plt.subplots(ncols=2, figsize=(24, 4))
ax[0].plot(thresh_range, train_acc_scores, '-o')
ax[0].set_title("Accuracy on Train Set")
ax[0].set_xlabel("Threshold")
ax[0].set_ylabel("Accuracy score")
ax[0].set_ylim([0.4, 1.05])
max_score = max(train_acc_scores)
max_loc = np.argmax(train_acc_scores)
ax[0].annotate(
    f'Max Accuracy: {max_score:.3f}',
    xy=(thresh_range[max_loc], max_score),
    xytext=(thresh_range[max_loc], max_score + 0.025),
    arrowprops=dict(facecolor='black', shrink=0.01),
)&lt;/p&gt;
&lt;p&gt;ax[1].plot(thresh_range, 1 - np.array(train_acc_scores), '-o')
ax[1].set_title("Error Train Set")
ax[1].set_xlabel("Threshold")
ax[1].set_ylabel("Error")
min_score = min(1 - np.array(train_acc_scores))
min_loc = np.argmin(1 - np.array(train_acc_scores))
ax[1].annotate(
    f'Min Error: {min_score:.3f}',
    xy=(thresh_range[min_loc], min_score),
    xytext=(thresh_range[min_loc], min_score + 0.025),
    arrowprops=dict(facecolor='black', shrink=0.01),
)&lt;/p&gt;
&lt;p&gt;fig.text(
    0.5,
    -0.1,
    'As the threshold increases we observe simultaneous increase in accuracy.\n'+\
    'As we cross the maximum accuracy, we essentially shift the hyperplane away from the data and thus see the decrease.',
    ha='center',
    fontsize=16);&lt;/p&gt;
&lt;p&gt;```&lt;/p&gt;
&lt;p&gt;&lt;img alt="png" src="https://iliailmer.github.io/images/2020-02-24-data-explore/output_26_0.png" /&gt;&lt;/p&gt;
&lt;h4 id="test-set-predictions"&gt;Test set predictions&lt;/h4&gt;
&lt;p&gt;We can do similar analysis on the testing set.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;python
y_true = y_test.copy().values
y_pred = linreg.predict(X_test)
test_acc_scores = []
for t in thresh_range:
    test_acc_scores.append(
        accuracy_score(y_pred=raw2label(y_pred, t), y_true=y_true))&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;```python
fig, ax = plt.subplots(ncols=2, figsize=(24, 6))
ax[0].plot(thresh_range, test_acc_scores, '-o')
ax[0].set_title("Accuracy on Test Set")
ax[0].set_ylim([0.4, 1.05])&lt;/p&gt;
&lt;h1 id="ax0set_xticksthresh_range"&gt;ax[0].set_xticks(thresh_range)&lt;/h1&gt;
&lt;p&gt;ax[0].set_xlabel("Threshold")
ax[0].set_ylabel("Accuracy score")&lt;/p&gt;
&lt;p&gt;max_score = max(test_acc_scores)
max_loc = np.argmax(test_acc_scores)
ax[0].annotate(
    f'Max Accuracy: {max_score:.3f}',
    xy=(thresh_range[max_loc], max_score),
    xytext=(thresh_range[max_loc] + 0.05, max_score + 0.05),
    arrowprops=dict(facecolor='black', shrink=0.01),
)&lt;/p&gt;
&lt;p&gt;ax[1].plot(thresh_range, 1 - np.array(test_acc_scores), '-o')
ax[1].set_title("Error Test Set")
ax[1].set_xlabel("Threshold")
ax[1].set_ylabel("Error")
ax[1].set_ylim([0, 0.55])
min_score = min(1 - np.array(test_acc_scores))
min_loc = np.argmin(1 - np.array(test_acc_scores))
ax[1].annotate(
    f'Min Error: {min_score:.3f}',
    xy=(thresh_range[min_loc], min_score),
    xytext=(thresh_range[min_loc] - 0.15, min_score - 0.03),
    arrowprops=dict(facecolor='black', shrink=0.01),
)&lt;/p&gt;
&lt;p&gt;fig.text(
    0.5,
    -0.1,
    'We observe a similar behaviour as the threshold increases.\n'+\
    'Notice that we use the same threshold as in the test set. '+\
    'The graphs converge around random guesses.',
    ha='center',
    fontsize=16);
```&lt;/p&gt;
&lt;p&gt;&lt;img alt="png" src="https://iliailmer.github.io/images/2020-02-24-data-explore/output_30_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;python
percentage = np.unique(y_test, return_counts=True)[1]/len(y_test) # proportion of each label in the training set
print(f'Minimal accuracy on the left: {min(test_acc_scores)}, proportion of "0" labels in the data: {percentage[0]}')
print(f'Minimal accuracy on the right: {test_acc_scores[-1]}, proportion of "1" labels in the data: {percentage[1]}')&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Minimal accuracy on the left: 0.46153846153846156, proportion of "0" labels in the data: 0.5439560439560439
Minimal accuracy on the right: 0.5467032967032966, proportion of "1" labels in the data: 0.45604395604395603
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;From the information above we learn that the model start to approximately randomly guess once the thresholds are too big or too small. On the left in is closer to guessing ones, on the right - zeros.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;python
print(f"Labels from leftmost threshold:\n{raw2label(y_pred, threshold=thresh_range[0])}")
print(f"\n\nLabels from rightmost threshold:\n{raw2label(y_pred, threshold=thresh_range[-1])}")&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Labels from leftmost threshold:
[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]


Labels from rightmost threshold:
[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let us use different thresholds for the testing set:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;python
y_true = y_test.copy().values
y_pred = linreg.predict(X_test)
thresh_range = np.arange(y_pred.min(), y_pred.max(), 0.1)
test_acc_scores = []
for t in thresh_range:
    test_acc_scores.append(
        accuracy_score(y_pred=raw2label(y_pred, t), y_true=y_true))&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;```python
fig, ax = plt.subplots(ncols=2, figsize=(24, 6))
ax[0].plot(thresh_range, test_acc_scores, '-o')
ax[0].set_title("Accuracy on Test Set")
ax[0].set_ylim([0.4, 1.05])&lt;/p&gt;
&lt;h1 id="ax0set_xticksthresh_range_1"&gt;ax[0].set_xticks(thresh_range)&lt;/h1&gt;
&lt;p&gt;ax[0].set_xlabel("Threshold")
ax[0].set_ylabel("Accuracy score")&lt;/p&gt;
&lt;p&gt;max_score = max(test_acc_scores)
max_loc = np.argmax(test_acc_scores)
ax[0].annotate(
    f'Max Accuracy: {max_score:.3f}',
    xy=(thresh_range[max_loc], max_score),
    xytext=(thresh_range[max_loc] + 0.05, max_score + 0.05),
    arrowprops=dict(facecolor='black', shrink=0.01),
)&lt;/p&gt;
&lt;p&gt;ax[1].plot(thresh_range, 1 - np.array(test_acc_scores), '-o')
ax[1].set_title("Error Test Set")
ax[1].set_xlabel("Threshold")
ax[1].set_ylabel("Error")
ax[1].set_ylim([0, 0.55])
min_score = min(1 - np.array(test_acc_scores))
min_loc = np.argmin(1 - np.array(test_acc_scores))
ax[1].annotate(
    f'Min Error: {min_score:.3f}',
    xy=(thresh_range[min_loc], min_score),
    xytext=(thresh_range[min_loc] - 0.15, min_score - 0.03),
    arrowprops=dict(facecolor='black', shrink=0.01),
)&lt;/p&gt;
&lt;p&gt;fig.text(
    0.5,
    -0.1,
    'We observe a similar behaviour as the threshold increases.\n'+\
    'Notice that we now see convergence to a random guess clearer. '+\
    'This is due to the threshold being intrinsic to the test set.',
    ha='center',
    fontsize=16);
```&lt;/p&gt;
&lt;p&gt;&lt;img alt="png" src="https://iliailmer.github.io/images/2020-02-24-data-explore/output_36_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;```python
percentage = np.unique(y_test, return_counts=True)[1] / len(
    y_test)  # proportion of each label in the training set
print(
    f'Minimal accuracy on the left: {min(test_acc_scores)},'
    + f' proportion of "0" labels in the data: {percentage[0]}'
)
print(
    f"Labels from leftmost threshold:\n{raw2label(y_pred, threshold=thresh_range[0])}"
)&lt;/p&gt;
&lt;p&gt;print(
    f'\n\nMinimal accuracy on the right: {test_acc_scores[-1]},' +
    f' proportion of "1" labels in the data: {percentage[1]}'
)
print(
    f"Labels from rightmost threshold: \n{raw2label(y_pred, threshold=thresh_range[-1])}"
)
```&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Minimal accuracy on the left: 0.45879120879120877, proportion of "0" labels in the data: 0.5439560439560439
Labels from leftmost threshold:
[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]


Minimal accuracy on the right: 0.5412087912087912, proportion of "1" labels in the data: 0.45604395604395603
Labels from rightmost threshold: 
[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id="k-nearest-neighbors"&gt;K-Nearest Neighbors&lt;/h3&gt;
&lt;p&gt;For this method, we consider different values of neighbors in each case. We begin with 1 neighbor per training point, which we expect to give a high accuracy since each point will roughly be each own neighborhood.&lt;/p&gt;
&lt;p&gt;As the number of neighbors increases we will see a slight decrease in accuracy.&lt;/p&gt;
&lt;p&gt;```python
train_err_scores = []
test_err_scores = []&lt;/p&gt;
&lt;p&gt;for k in [1, 3, 5, 7, 15]:
    knn = KNeighborsClassifier(n_neighbors=k)
    knn.fit(X, y)&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;y_true = y.copy().values
y_pred = knn.predict(X)

train_err_scores.append(1 - accuracy_score(y_pred=y_pred, y_true=y_true))

y_true = y_test.copy().values
y_pred = knn.predict(X_test)
test_err_scores.append(1 - accuracy_score(y_pred=y_pred, y_true=y_true))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;```&lt;/p&gt;
&lt;p&gt;```python
fig, ax = plt.subplots(ncols=2, figsize=(24, 6))
ax[1].plot([1, 3, 5, 7, 15], train_err_scores, '-o')
ax[1].set_title("Error on Train Set")
ax[1].set_xlabel("Neighbors")
ax[1].set_ylabel("Error score")&lt;/p&gt;
&lt;p&gt;ax[0].plot([1, 3, 5, 7, 15], test_err_scores, '-o')
ax[0].set_title("Error on Test Set")
ax[0].set_xlabel("Neighbors")
ax[0].set_ylabel("Error score")&lt;/p&gt;
&lt;p&gt;fig.text(
    0.5,
    -0.1,
    'As the number of neighbors increases, so does the error score of the model on the training data.',
    ha='center',
    fontsize=16);
```&lt;/p&gt;
&lt;p&gt;&lt;img alt="png" src="https://iliailmer.github.io/images/2020-02-24-data-explore/output_41_0.png" /&gt;&lt;/p&gt;
&lt;h2 id="conclusion"&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;We applied two different classification methods for the data. Method 1 was based on the linear regression using least squares method. The second method was based on 5 different Nearest neighbor classifiers.&lt;/p&gt;
&lt;p&gt;Each approach showed different results specific to assumptions underlying each model. Linear model assumes that the relationship between the label and pixel intensities is a high-dimensional linear function. Using various threshold we were able to show the change in hyperplane location relative to test and train data and how the accuracy scores (error scores) reflect this change.&lt;/p&gt;
&lt;p&gt;For the k-NN model, we observed a similar behavior: going from few neighbors to more, we saw that the model is prone to the larger error. This is to be expected but not to say that 1 neighbor is necessarily better than 15 neighbors, since 1 neighbor case is &lt;em&gt;overfitting&lt;/em&gt; the data. The data is very high-dimensional so it is harder to evaluate how many neighbors we should aim for here.&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="Posts"></category><category term="machine learning"></category><category term="linear regression"></category><category term="python"></category><category term="scikit-learn"></category><category term="statistical learning"></category></entry><entry><title>How to write a decent training loop with enough flexibility.</title><link href="https://iliailmer.github.io/2019/06/how-to-make-training-loop.html" rel="alternate"></link><published>2019-06-15T00:00:00-04:00</published><updated>2019-06-15T00:00:00-04:00</updated><author><name>Ilia Ilmer</name></author><id>tag:iliailmer.github.io,2019-06-15:/2019/06/how-to-make-training-loop.html</id><summary type="html">&lt;p&gt;In this post, I briefly describe my experience in setting up training with PyTorch.&lt;/p&gt;
&lt;h2 id="introduction"&gt;Introduction&lt;/h2&gt;
&lt;p&gt;PyTorch is an extremely useful and convenient framework for deep learning. When it comes to working on  a deep learning project, I am more comfortable with PyTorch rather than TensorFlow.&lt;/p&gt;
&lt;p&gt;In this quick post, I …&lt;/p&gt;</summary><content type="html">&lt;p&gt;In this post, I briefly describe my experience in setting up training with PyTorch.&lt;/p&gt;
&lt;h2 id="introduction"&gt;Introduction&lt;/h2&gt;
&lt;p&gt;PyTorch is an extremely useful and convenient framework for deep learning. When it comes to working on  a deep learning project, I am more comfortable with PyTorch rather than TensorFlow.&lt;/p&gt;
&lt;p&gt;In this quick post, I would like to show how one can go about building a custom training loop, something that I struggled when I was getting started. It is a useful skill to be able to build the training loop on your own because that can help you understand better what happens under the hood of a deep learning package that abstracts a lot of nuts and bolts away from the end-user.&lt;/p&gt;
&lt;h2 id="the-overview-of-training"&gt;The Overview of Training&lt;/h2&gt;
&lt;p&gt;When one trains a network, we need to follow a certain paradigm.&lt;/p&gt;
&lt;p&gt;First, set the model into training mode.&lt;/p&gt;
&lt;p&gt;Second, start iterating through the training set.&lt;/p&gt;
&lt;p&gt;For every batch we must:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;compute the output of the network&lt;/li&gt;
&lt;li&gt;compute the loss&lt;/li&gt;
&lt;li&gt;get gradients&lt;/li&gt;
&lt;li&gt;start descending using the optimizer&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This last step we acknowledge that the method for optimization of our model is based on a gradient descent. It can be eqither Adam, SGD, or any other (RAdam is the brand new one which seems to beat state of the art).&lt;/p&gt;
&lt;p&gt;In code, we can put it in the form like this:&lt;/p&gt;
&lt;p&gt;```python
def train(epoch):
  model.train()  # preparing model for training
  for batch in training_set:
    x, y = batch  # unpack the batch
    # the step below is necessary so that we update the gradient only pertinent to the current batch
    optimizer.zero_grad()
    # compute the output
    output = model(x.cuda())
    # calculate the loss function
    loss = criterion(output, y.cuda())
    # calculate the gradient using backpropagation
    loss.backward()
    # take a step with the optimizer
    optimizer.step()&lt;/p&gt;
&lt;p&gt;```&lt;/p&gt;
&lt;h3 id="a-trick-for-better-training-with-lower-memory"&gt;A Trick for Better Training with Lower Memory&lt;/h3&gt;
&lt;p&gt;A small batch can result in a small gradient. This, in turn, leads to a problem called &lt;a href="https://en.wikipedia.org/wiki/Vanishing_gradient_problem"&gt;vanishing gradient problem&lt;/a&gt;: the value is so small, computer simple treats it as zero (underflow). To avoid it, a trick of accumulating gradient as you iterate through the dataset. I saw a practical implementation in this &lt;a href="https://www.kaggle.com/c/understanding_cloud_organization/discussion/105614#latest-662360"&gt;discussion&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;python
def train_accumulate(epoch, accumulation_step = 1):
  model.eval()  # preparing model for training
  for idx, batch in enumerate(training_set):
    x, y = batch  # unpack the batch
    # compute the output
    output = model(x.cuda())
    # calculate the loss function
    loss = criterion(output, y.cuda())
    # calculate the gradient using backpropagation
    loss.backward()
    if idx%accumulation_step==0:
      # take a step with the optimizer once
      # we accumulated enough gradients
      optimizer.step()
      optimizer.zero_grad()&lt;/code&gt;&lt;/p&gt;
&lt;h2 id="in-closing-abstracting-training-loop"&gt;In Closing: abstracting training loop&lt;/h2&gt;
&lt;p&gt;In this post I summarized my experience in building a training loop for PyTorch. Lately, I have been using a more abstracted way of training through &lt;a href="https://catalyst-team.github.io/catalyst/"&gt;Catalyst&lt;/a&gt;. It is a great tool for higher level abstraction during training and a lot of hardwork has been done to take away the hard part of training.&lt;/p&gt;
&lt;p&gt;Nevertheless, both, I believe, are equally important: the abstract and the explicit methods.&lt;/p&gt;
&lt;p&gt;Thanks for reading!&lt;/p&gt;</content><category term="Posts"></category><category term="deep learning"></category></entry><entry><title>RiCNN and Rotation Robustness of ConvNets. A Paper Review</title><link href="https://iliailmer.github.io/2019/06/paper-review.html" rel="alternate"></link><published>2019-06-15T00:00:00-04:00</published><updated>2019-06-15T00:00:00-04:00</updated><author><name>Ilia Ilmer</name></author><id>tag:iliailmer.github.io,2019-06-15:/2019/06/paper-review.html</id><summary type="html">&lt;p&gt;Lately, I have been reading more papers on modern advances in deep learning in order to get a clear view of what problem I want to focus on during my PhD research.&lt;/p&gt;
&lt;p&gt;There is a lot of information to process and an incredible amount of papers are being published from …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Lately, I have been reading more papers on modern advances in deep learning in order to get a clear view of what problem I want to focus on during my PhD research.&lt;/p&gt;
&lt;p&gt;There is a lot of information to process and an incredible amount of papers are being published from all over the world.&lt;/p&gt;
&lt;p&gt;In order to keep up, I will do my best to document everything that I read in this weekly series of paper reviews. The aim is to post one review a week and go from there.&lt;/p&gt;
&lt;p&gt;The first paper I will talk about is the one by &lt;a href="https://arxiv.org/abs/1805.12301"&gt;Chidester, Do, and Ma&lt;/a&gt; titled &lt;strong&gt;Rotation Equivariance and Invariance in Convolutional Neural Networks&lt;/strong&gt;.&lt;/p&gt;
&lt;h1 id="what-is-the-key-problem"&gt;What is the key problem?&lt;/h1&gt;
&lt;p&gt;The advantage of convnets over other algorithms is in the amount of different features such network extracts from a given input. Convnets are a very powerful and form a very ubiquitous family of algorithms with various applications in industry.&lt;/p&gt;
&lt;p&gt;When it comes to image classification, the same image or the same object in the image could be presented in various positions: it could be shifted left or right, and even rotated. The shift, or, &lt;em&gt;translation&lt;/em&gt;, is something the network can withstand. The problem arises when the input is rotated.&lt;/p&gt;
&lt;p&gt;If the network has never seen this rotated image, the result of classification will be wrong regardless of whether or not the net has seen the &lt;em&gt;un&lt;/em&gt;-rotated original. This originates in the nature of the convolution: the operation of sliding the feature extracting kernel along the image (&lt;a href="https://ezyang.github.io/convolution-visualizer/index.html"&gt;this&lt;/a&gt; is an excellent depiction of convolution).&lt;/p&gt;
&lt;p&gt;&lt;img alt="convolution" src="https://cdn-images-1.medium.com/max/1600/1*1okwhewf5KCtIPaFib4XaA.gif" /&gt;
Convolution in its natural habitat: a blog post.&lt;/p&gt;
&lt;p&gt;One common way of dealing with this is to rotate by a random angle images in the input. This is called &lt;em&gt;augmentation&lt;/em&gt; and it increases the number of input data, which in turn may increase training time. Such trade-off is undesirable: why increase training time and sacrifice memory for a super-large network with hundreds of thousands of images already at hand?&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Side note:&lt;/strong&gt; not to say that augmentation is a bad technique. Quite the &lt;a href="http://cs231n.stanford.edu/reports/2017/pdfs/300.pdf"&gt;opposite&lt;/a&gt;, it is a very powerful way to avoid overfitting.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;So here is the problem: how can the network learn image transformation without explicitly seeing the transformed image during training?&lt;/p&gt;
&lt;h1 id="rotation-equivariance"&gt;Rotation Equivariance&lt;/h1&gt;
&lt;p&gt;In the second section of the paper, the authors propose a multi-stage approach to dealing with rotations.&lt;/p&gt;
&lt;p&gt;Stage 1 is rotation equivariance, stage 2 is a rotation invariant layer in the network just before the fully-connected classifier block, and stage 3 is the fully-connected layer itself.&lt;/p&gt;
&lt;h3 id="rotation-equivariance_1"&gt;Rotation Equivariance&lt;/h3&gt;
&lt;p&gt;The term equivariance when applied to rotation transformation means the following: if a function
&lt;img alt="F" src="http://mathurl.com/render.cgi?%5Cinlinemode%20%5Cmathcal%7BF%7D%5Cnocache" /&gt; acts on an input &lt;img alt="x" src="http://mathurl.com/render.cgi?%5Cinlinemode%20x%5Cnocache" /&gt; then the result is&lt;img alt="y" src="http://mathurl.com/render.cgi?%5Cinlinemode%20y%20%3D%20%5Cmathcal%7BF%7D%28x%29%5Cnocache" /&gt;. If the input is "corrupted" by a transformation &lt;img alt="T" src="http://mathurl.com/render.cgi?%5Cinlinemode%20%5Cmathrm%7BT%7D%5Cnocache" /&gt; (rotation, shift, etc.), then &lt;em&gt;equivariance with respect to&lt;/em&gt; &lt;img alt="T" src="http://mathurl.com/render.cgi?%5Cinlinemode%20%5Cmathrm%7BT%7D%5Cnocache" /&gt; implies existence of a transform &lt;img alt="S" src="http://mathurl.com/render.cgi?%5Cinlinemode%20%5Cmathrm%7BS%7D%5Cnocache" /&gt; such that:&lt;/p&gt;
&lt;p&gt;&lt;img alt="F(Tx)=S(F(x))" src="http://mathurl.com/render.cgi?%5Cinlinemode%20%5Cmathcal%7BF%7D%28%5Cmathrm%7BT%7Dx%7D%29%20%3D%20%5Cmathrm%7BS%7D%28%5Cmathcal%7BF%7D%28x%29%29%5Cnocache" /&gt;.&lt;/p&gt;
&lt;p&gt;The invariance property would look like this:&lt;/p&gt;
&lt;p&gt;&lt;img alt="F(Tx) = F(x)" src="http://mathurl.com/render.cgi?%5Cinlinemode%20%5Cmathcal%7BF%7D%28%5Cmathrm%7BT%7Dx%7D%29%20%3D%20%5Cmathcal%7BF%7D%28x%29%5Cnocache" /&gt;.&lt;/p&gt;
&lt;h1 id="proposed-solution"&gt;Proposed Solution&lt;/h1&gt;
&lt;h3 id="rotation-of-the-filters"&gt;Rotation of the Filters&lt;/h3&gt;
&lt;p&gt;What the authors proposed is to connect rotation of the input with that of the feature extractor explicitly. To elaborate, the convolutional kernel is, essentially, rotated for a desired range of angles. At the same time, the image is split into conic regions, each region will have a designated rotated copy of the convolution kernel. Each rotated kernel is applied to the region.&lt;/p&gt;
&lt;p&gt;This formulation opens up a new formalism: a conic convolution.&lt;/p&gt;
&lt;p&gt;&lt;img alt="diagram" src="https://iliailmer.github.io/images/ricnn-paper-review/diagram.png" /&gt;
Diagram of the proposed network by &lt;a href="https://arxiv.org/abs/1805.12301"&gt;Chidester, Do, and Ma&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The authors prove a very interesting property of this network. Essentially, the rotation equivariance property we stated still holds, according the results, however, &lt;img alt="T" src="http://mathurl.com/render.cgi?%5Cinlinemode%20%5Cmathrm%7BT%7D%5Cnocache" /&gt; is equal to &lt;img alt="F" src="http://mathurl.com/render.cgi?%5Cinlinemode%20%5Cmathcal%7BF%7D%5Cnocache" /&gt;. (This is proven in Theorem 1 of the article.)&lt;/p&gt;
&lt;h3 id="discrete-fourier-transform-dft"&gt;Discrete Fourier transform (DFT)&lt;/h3&gt;
&lt;p&gt;After that, the results of the conic section of the network need proceed to an additional section before the fully-connected one. It is required to preserve the rotation equivariance extracted by the conic portion before unravelling the tensors.&lt;/p&gt;
&lt;p&gt;Such encoding of the equivariance is achieved through the DFT procedure. The authors note the cyclical property of the last convolutional with respect to rotation order. Applying  DFT to the output of this convolution yields a representation in which the rotation is "hard-coded".&lt;/p&gt;
&lt;p&gt;Finally, this representation is passed into the fully connected layer.&lt;/p&gt;
&lt;h1 id="conclusion"&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;I will not focus this review on the results of the work when applied to benchmark datasets, I believe it is only fair that one refers to the &lt;a href="https://arxiv.org/abs/1805.12301"&gt;paper&lt;/a&gt; itself for that.&lt;/p&gt;
&lt;p&gt;Rotation equivariance and general robustness of neural networks to external peturbations is important and in applications such as medical imaging, where the data can be the same image from different angles (or with different transformations applied), a neural network must return a faulty result as the life of a patient is on the line.&lt;/p&gt;</content><category term="Posts"></category><category term="review series"></category><category term="deep learning"></category><category term="computer vision"></category></entry><entry><title>Computer Vision: Can You Teach a Machine To See?</title><link href="https://iliailmer.github.io/2019/03/science-day.html" rel="alternate"></link><published>2019-03-22T00:00:00-04:00</published><updated>2019-03-22T00:00:00-04:00</updated><author><name>Ilia Ilmer</name></author><id>tag:iliailmer.github.io,2019-03-22:/2019/03/science-day.html</id><summary type="html">&lt;p&gt;A little overview of what I talked about at CUNY CSI Science Day.&lt;/p&gt;
&lt;p&gt;During the Science Day at the CUNY College of Staten Island, I presented a gentle introduction to area of computer vision with fun examples and research results to visiting middle and high school students.&lt;/p&gt;
&lt;p&gt;It was a …&lt;/p&gt;</summary><content type="html">&lt;p&gt;A little overview of what I talked about at CUNY CSI Science Day.&lt;/p&gt;
&lt;p&gt;During the Science Day at the CUNY College of Staten Island, I presented a gentle introduction to area of computer vision with fun examples and research results to visiting middle and high school students.&lt;/p&gt;
&lt;p&gt;It was a very interesting experience given the target audience without any experience (or, at least, presumably) in the subject. I aimed at being user friendly by showing some of the most ground-breaking online projects.&lt;/p&gt;
&lt;p&gt;My favorite part of the talk was when we played a little game of "Do you know who this person is?" with fake images from GANs. The reactions were priceless and the interest unmistakably there.&lt;/p&gt;
&lt;p&gt;I finished the talk with a bit of a diversion for those who might be interested in trying stuff on their own:
Kaggle, FastAI, and Python (which quite a lot of them are already familiar with!) were all mentioned as something to try out.&lt;/p&gt;
&lt;!-- The slides for the talk can be viewed [here]({static}/files/2019-03-22-science-day.pdf) --&gt;</content><category term="Posts"></category><category term="education"></category><category term="talks"></category></entry><entry><title>Harmonic networks: implementation of paper results</title><link href="https://iliailmer.github.io/2019/03/harmonic-network/.html" rel="alternate"></link><published>2019-03-10T00:00:00-05:00</published><updated>2019-03-10T00:00:00-05:00</updated><author><name>Ilia Ilmer</name></author><id>tag:iliailmer.github.io,2019-03-10:/2019/03/harmonic-network/.html</id><summary type="html">&lt;p&gt;I implement an interesting result from a recent paper on convolutional neural networks.&lt;/p&gt;
&lt;h1 id="introduction"&gt;Introduction&lt;/h1&gt;
&lt;p&gt;In this post I will briefly discuss my implementation of a model introduced in &lt;a href="https://arxiv.org/abs/1812.03205v1"&gt;this paper&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In short, the authors suggest using predefined filters in a convolutional network based on Discrete Cosine Transform.&lt;/p&gt;
&lt;p&gt;I used PyTorch …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I implement an interesting result from a recent paper on convolutional neural networks.&lt;/p&gt;
&lt;h1 id="introduction"&gt;Introduction&lt;/h1&gt;
&lt;p&gt;In this post I will briefly discuss my implementation of a model introduced in &lt;a href="https://arxiv.org/abs/1812.03205v1"&gt;this paper&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In short, the authors suggest using predefined filters in a convolutional network based on Discrete Cosine Transform.&lt;/p&gt;
&lt;p&gt;I used PyTorch for neural network implementation, the other packages include &lt;code&gt;pandas&lt;/code&gt; for data reading,
&lt;code&gt;numpy, scipy, skimage&lt;/code&gt;, etc.&lt;/p&gt;
&lt;p&gt;The dataset I was using is the &lt;a href="https://www.kaggle.com/kmader/skin-cancer-mnist-ham10000"&gt;skin cancer MNIST&lt;/a&gt; from Kaggle.&lt;/p&gt;
&lt;p&gt;I really enjoyed working on this project! However, it is still far from being complete and I will try to fix some errors it has in due time.&lt;/p&gt;
&lt;h1 id="paper-summary"&gt;Paper summary&lt;/h1&gt;
&lt;p&gt;In this paper, the authors propose a modification to the common algorithm of convolutional neural networks.&lt;/p&gt;
&lt;p&gt;Classically, such networks are comprised of convolutional layers. Each layer, in turn, has a corresponding amount of kernels which are slided over the input during convolution (&lt;a href="https://ujjwalkarn.me/2016/08/11/intuitive-explanation-convnets/"&gt;see visualization here&lt;/a&gt;). As the input is carried through the network, in the final, non-convolutional (fully-connected) layer the network measure the error between the true label/value and the prediction is carried backwards through back propagation algorithm. That way the weights (kernels) are adjusted to accommodate for the discrepancy in prediction and improve feature extraction, which is the primary purpose of convolutional layers.&lt;/p&gt;
&lt;p&gt;The paper, however, considers a different approach to convolutional neural networks. In suggested algorithm, the net's layers are predefined by decomposition of the input according to the Discrete Cosine Transform (the DCT). The &lt;a href="https://en.wikipedia.org/wiki/Discrete_cosine_transform"&gt;DCT&lt;/a&gt; is a method for feature extraction that is based on &lt;a href="https://en.wikipedia.org/wiki/Fourier_transform"&gt;Fourier Transform&lt;/a&gt;. It separates frequencies that comprise the input signal from itself and thus produce features (the frequency spectrum).&lt;/p&gt;
&lt;p&gt;The authors use convolutional  approach to computing the Discrete Cosine transform, building filters that result in equivalent mathematical formulations upon convolution. Using these filters as kernels in CNN, they construct a Harmonic Network. Such network can be computationally expensive (more on that later), but it is able to show state of the art results on common image datasets such as CIFAR10.&lt;/p&gt;
&lt;p&gt;The harmonic block that replaces the usual convolutional layer consists of a linear combination of features from the DCT of the input from the previous layer. These features can optionally be batch normalized.&lt;/p&gt;
&lt;h1 id="difficulties-in-implementation"&gt;Difficulties in implementation&lt;/h1&gt;
&lt;p&gt;Let me discuss some difficulties I ran into when I was implementing the network. I will try to be as brief as I can.&lt;/p&gt;
&lt;h2 id="finding-the-right-kernel-filter-bank"&gt;Finding the right kernel (filter bank)&lt;/h2&gt;
&lt;p&gt;Firs of all, representing the DCT as a convolution sounds intuitively simple but turned out to be more difficult in practice. Let's look at the formula transforming the 2D N-by-N input signal &lt;span class="math"&gt;\(x\)&lt;/span&gt; into 2D output signal &lt;span class="math"&gt;\(\hat X\)&lt;/span&gt;:&lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\(\hat X_{u,v} = \sum_{ii=0}^{N-1}\left[\sum_{jj=0}^{N-1} x_{ii,jj} \cos\left(\frac{\pi}{N}\left(ii+0.5\right) u \right)\right] \cos\left(\frac{\pi}{N}\left(jj+0.5\right) v \right).\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;So the approach is to use a separate kernel for each combination of &lt;span class="math"&gt;\((u,~v)\)&lt;/span&gt; indices. They will implicitly represent the direction in which our filter is looking at the image.&lt;/p&gt;
&lt;p&gt;So, if our sliding convolution window is &lt;span class="math"&gt;\(N\times N\)&lt;/span&gt; then we need &lt;span class="math"&gt;\(N^2\)&lt;/span&gt; filters, &lt;span class="math"&gt;\(N\times N\)&lt;/span&gt; each:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;py
import torch
import numpy as np
PI = np.pi
def fltr(u, v, N, k): # note, that I will always use N=k and N=K in where
                      # but we can have N&amp;gt;K. I have not tried N&amp;lt;K,
                      # it'd be pretty cool to try that as well
  return torch.as_tensor([[torch.cos(torch.as_tensor(v*PI/N*(ii+0.5)))
                           * torch.cos(torch.as_tensor(u*PI/N*(jj+0.5)))
                           for ii in range(k)] for jj in range(k)])&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;So, once we get the necessary filters, we need to properly collect them into the so-called &lt;em&gt;filter bank&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;```py
import torch
def get_filter_bank(input_channels, N, K):&lt;/p&gt;
&lt;p&gt;filter_bank = torch.stack([torch.stack([fltr(j, i, N, K)
                                          for i in range(K)]) for j in range(K)])
  filter_bank = filter_bank.reshape([-1, 1, K, K])
  filter_bank = torch.cat([filter_bank]*input_channels, dim=1)
  filter_bank = filter_bank.to('cuda')
  return filter_bank
```&lt;/p&gt;
&lt;p&gt;Great, the filters are collected. The cool thing with PyTorch is that by default these tensors will not be updated in the backwards pass. This is because the property called &lt;code&gt;requires_grad&lt;/code&gt; is initialized to &lt;code&gt;False&lt;/code&gt; automatically. (I should probably add that it can always be manipulated manually, but we will not worry about that here.)&lt;/p&gt;
&lt;h2 id="further-processing-of-harmonic-blocks"&gt;Further processing of harmonic blocks&lt;/h2&gt;
&lt;p&gt;One convolution with kernels is not enough. The authors propose a way of combining them linearly through &lt;span class="math"&gt;\(1\times1\)&lt;/span&gt; convolution. That way each consequent layer is a linear combination of the previous one. This convolution &lt;strong&gt;is&lt;/strong&gt; affected by the backwards pass. The linear combination occurs across the result of convolution with DCT filters.&lt;/p&gt;
&lt;p&gt;If the input has 3 channels and each channel produces 9 convolution results (&lt;span class="math"&gt;\(3\times 3\)&lt;/span&gt; filters, 9 of them)
then we get the output shape after the harmonic block as (3,9,W,H) where W and H are width and height respectively. The linear combination than happens across the &lt;strong&gt;9&lt;/strong&gt; outputs for each channel. That's it!&lt;/p&gt;
&lt;h2 id="sending-to-gpu-device-using-torchcuda"&gt;Sending to GPU device using &lt;code&gt;torch.cuda()&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;A problem I encountered while implementing the Harmonic block of the network was that just sending the model to GPU using&lt;/p&gt;
&lt;p&gt;&lt;code&gt;py
model.cuda()&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;is not enough. I had to "manually" send the convolution weights. Note that it's not really manually as in "low-level" but rather this line of code from before:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;py
filter_bank = filter_bank.to('cuda')&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Not sure why the model does not send the DCT filters upon regular GPU sending but manually it all works.&lt;/p&gt;
&lt;h2 id="selecting-learning-rate"&gt;Selecting learning rate&lt;/h2&gt;
&lt;p&gt;Another problem was the learning rate. From lessons on &lt;a href="https://fast.ai"&gt;FastAI&lt;/a&gt; I learned that trying the learning rate of 0.01 is quite common (the amazing function for finding a proper learning rate consistently recommends doing so across multiple CNN models). However, in here, we get quite rapid loss increase!&lt;/p&gt;
&lt;h3 id="update-march2019"&gt;Update, March,2019&lt;/h3&gt;
&lt;p&gt;Experimenting with learning rate finding yielded that 0.001 learning rate with &lt;em&gt;Adam&lt;/em&gt; optimizer works really well for my architecture, especially on an unbalanced &lt;a href="https://arxiv.org/abs/1803.10417"&gt;dataset&lt;/a&gt; I use for my research.&lt;/p&gt;
&lt;h2 id="image-preprocessing-added-march2019"&gt;Image preprocessing, added March,2019&lt;/h2&gt;
&lt;p&gt;In the preprocessing stage, the images are downsized to 64 by 64 pixels using &lt;code&gt;skimage&lt;/code&gt; library. Originals in the dataset used are 450 by 600, which can take too much of the memory.&lt;/p&gt;
&lt;p&gt;Additional preprocessing consists of hair removal described in &lt;a href="https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.13.3821&amp;amp;rep=rep1&amp;amp;type=pdf"&gt;this paper&lt;/a&gt;.&lt;/p&gt;
&lt;h1 id="result"&gt;Result&lt;/h1&gt;
&lt;p&gt;Although it overfits during training, the model gives ~84% in both precision and recall which is pretty nice.&lt;/p&gt;
&lt;h1 id="summary"&gt;Summary&lt;/h1&gt;
&lt;p&gt;I really enjoyed working on the implementation. I learned a lot about how PyTorch works and how to use it when building a model from scratch.&lt;/p&gt;
&lt;p&gt;Even though this is still a work in progress for me, I will be gradually improving the implementation as much as I can, time permitting. Some things I plan to do&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Improve metrics on testing set&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Experiment with binarization of weights: to decrease model size&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The implementation of the model can be found &lt;a href="https://github.com/iliailmer/harmonic_network"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="Posts"></category><category term="deep learning"></category><category term="computer vision"></category><category term="work in progress"></category></entry><entry><title>Image Quality Measure</title><link href="https://iliailmer.github.io/2018/12/image-quality/.html" rel="alternate"></link><published>2018-12-13T00:00:00-05:00</published><updated>2018-12-13T00:00:00-05:00</updated><author><name>Ilia Ilmer</name></author><id>tag:iliailmer.github.io,2018-12-13:/2018/12/image-quality/.html</id><summary type="html">&lt;p&gt;A simple function that can be used to justify image quality and control enhancement.&lt;/p&gt;
&lt;h1 id="introduction"&gt;Introduction&lt;/h1&gt;
&lt;p&gt;One difficult thing about image enhancement is to actually measure the level of image quality which is quite a subjective task. On the one hand, each individual can perceive the image quality according to their …&lt;/p&gt;</summary><content type="html">&lt;p&gt;A simple function that can be used to justify image quality and control enhancement.&lt;/p&gt;
&lt;h1 id="introduction"&gt;Introduction&lt;/h1&gt;
&lt;p&gt;One difficult thing about image enhancement is to actually measure the level of image quality which is quite a subjective task. On the one hand, each individual can perceive the image quality according to their own tastes and preferences. On the other hand, our visual system is the same for all of us, no matter what tastes you have.&lt;/p&gt;
&lt;p&gt;An interesting measure that goes forward to unify the subjectivity of human taste and the visual system based perspective was introduced in &lt;a href="https://pdfs.semanticscholar.org/5ada/c5932775f089eaace7ebc45a6cba89809134.pdf"&gt;this paper&lt;/a&gt;. Let's try it out!&lt;/p&gt;
&lt;h1 id="code"&gt;Code&lt;/h1&gt;
&lt;p&gt;Well, the essential idea of this measure is that we focus our attention on the image in a blockwise manner. Splitting the image into blocks and then finding the maximal value of the pixel intensity per each block is fairly straightforward and simple to code.&lt;/p&gt;
&lt;p&gt;We split the &lt;span class="math"&gt;\(M\times N\)&lt;/span&gt; image, which in computer memory is represented as a matrix of pixel intensities, into submatrices each of size &lt;span class="math"&gt;\(n\times n\)&lt;/span&gt;. This results in &lt;span class="math"&gt;\(k_1\)&lt;/span&gt; blocks along the vertical axis of the image and &lt;span class="math"&gt;\(k_2\)&lt;/span&gt; along the horizontal one. The quality measure can be used&lt;/p&gt;
&lt;div class="math"&gt;$$\sum_{l=1}^{k_1}\sum_{p=1}^{k_2}\frac{\max(W_{lp})}{\min(W_{lp})}.$$&lt;/div&gt;
&lt;p&gt;To avoid division by zero, what I do (and this seems to preserve the measure's main purpose) is the following&lt;/p&gt;
&lt;div class="math"&gt;$$\sum_{l=1}^{k_1}\sum_{p=1}^{k_2}\frac{\max(W_{lp}+1)}{\min(W_{lp}+1)}.$$&lt;/div&gt;
&lt;p&gt;The addition &lt;span class="math"&gt;\(W_{lp}+1\)&lt;/span&gt; implies that we add 1 to all elements in the window &lt;span class="math"&gt;\(W_{lp}\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;I prefer to scale image to have intensities between 0 and 1, but it really is not important, you can use any range as long as it is &lt;code&gt;float&lt;/code&gt; type. This is because of the nature of the division and &lt;span class="math"&gt;\(\log\)&lt;/span&gt; operators.&lt;/p&gt;
&lt;p&gt;And here's the code for this function:
&lt;code&gt;python
def EME(image, window_width, window_height):
  height, width = image.shape
  sum_ = 0
  k = 0                                    # I just decided not to keep
                                           # track of the blocks
  # window_height/ window_width variables take care of number of blocks
  H = np.int(np.floor(window_height / 2))  # range in height, distance from the
                                           # center of the window
  W = np.int(np.floor(window_width / 2))   # range in width, same as above
  for row in range(0 + H, height - H + 1, window_height):
      for column in range(0 + W, width - W + 1, window_width):
        window = image[row - H:row + H + 1, column - W:column + W + 1]
        I_max = window.max()
        I_min = window.min()
        D = (I_max + 1) / (I_min + 1)
        if D &amp;lt; 0.02: # this is also an underflow precaution
          D = 0.02
        k += 1
        sum_ += 20 * np.log(D)
      return sum_ / k&lt;/code&gt;&lt;/p&gt;
&lt;h1 id="examples"&gt;Examples&lt;/h1&gt;
&lt;p&gt;Let's try it out on some examples. What I am going to do here is, I will use the &lt;code&gt;skimage&lt;/code&gt; library to obtain the data first.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;py
from skimage.data import camera() # my favourite at this point&lt;/code&gt;&lt;/p&gt;
&lt;figure&gt;
  &lt;img src="https://iliailmer.github.io/images/enhancement-measure/camera.png?raw=true" alt="original"/&gt;
  &lt;figcaption&gt;My favourite sample image.&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;And then lets use simple histogram equalization for image enhancement. This function will enhance the contrast of the image and will bring some details (but also noise! Don't 100% rely on it!)
```py
from skimage.data import camera
from skimage.restoration import denoise_bilateral, denoise_wavelet&lt;/p&gt;
&lt;p&gt;original = camera()
enhanced = equalize_hist(original)
image = rescale(enhanced, 0, 255).astype("uint8")
```
And the result is pretty evident&lt;/p&gt;
&lt;figure&gt;
  &lt;img src="https://iliailmer.github.io/images/enhancement-measure/camera_enh.png?raw=true" alt="comparison"/&gt;
  &lt;figcaption&gt;Quality comparison.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Of course, histogram equalization produces artifacts, but visually the image is more detailed than originally which corresponds to increase in the measure, which is what we wanted from it in the first place!&lt;/p&gt;
&lt;h1 id="question"&gt;Question&lt;/h1&gt;
&lt;p&gt;A question that I have for EME, so far just one, but I feel like it's important.&lt;/p&gt;
&lt;h3 id="how-can-we-make-it-more-resistant-to-noise"&gt;How can we make it more resistant to noise?&lt;/h3&gt;
&lt;p&gt;It does decrease for small amounts of noise:&lt;/p&gt;
&lt;figure&gt;
  &lt;img src="https://iliailmer.github.io/images/enhancement-measure/camera_noise_sigma_1.png?raw=true" alt="comparison"/&gt;
  &lt;figcaption&gt;Adding Gaussian noise to the image (right) with $\sigma=1$ decreases the quality measure.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;But once noise is pretty strong:&lt;/p&gt;
&lt;figure&gt;
  &lt;img src="https://iliailmer.github.io/images/enhancement-measure/camera_noise_sigma_10.png?raw=true" alt="comparison"/&gt;
  &lt;figcaption&gt;Adding Gaussian noise to the image (right) with $\sigma=10$ increases the quality measure.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;This is not good, particularly when the enhancement we perform somewhere implicitly brings large noise (such as histogram equalization!) forcing us to believe that the quality improved.&lt;/p&gt;
&lt;p&gt;The explanation is, of course, that due to random noise, we (with non-zero probability) increase the maximal and decrease the minimal values of pixels and thus cause the change in the final metric value.&lt;/p&gt;
&lt;p&gt;But how to make the metric more noise-robust?..&lt;/p&gt;
&lt;p&gt;Well, there are certainly options. Some extensions listed &lt;a href="https://ieeexplore.ieee.org/abstract/document/6626251/"&gt;here&lt;/a&gt; certainly could do the job and be noise-resistant. But this is probably for some future experiments, who knows!&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="Posts"></category><category term="image enhancement"></category><category term="image quality"></category></entry><entry><title>A surprising way sigmoid function is applied in computer vision</title><link href="https://iliailmer.github.io/2018/11/image-enhancement/.html" rel="alternate"></link><published>2018-11-30T00:00:00-05:00</published><updated>2018-11-30T00:00:00-05:00</updated><author><name>Ilia Ilmer</name></author><id>tag:iliailmer.github.io,2018-11-30:/2018/11/image-enhancement/.html</id><summary type="html">&lt;p&gt;Let's talk about all things image enhancement, what it is, why it is necessary and how do wavelets play a big part in it!&lt;/p&gt;
&lt;h1 id="introduction"&gt;Introduction&lt;/h1&gt;
&lt;p&gt;Enhancement of images is an important preprocessing step in any image related system. Getting rid of noise, brightening, extraction of details - all of this helps …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Let's talk about all things image enhancement, what it is, why it is necessary and how do wavelets play a big part in it!&lt;/p&gt;
&lt;h1 id="introduction"&gt;Introduction&lt;/h1&gt;
&lt;p&gt;Enhancement of images is an important preprocessing step in any image related system. Getting rid of noise, brightening, extraction of details - all of this helps in future steps, like feature extraction/engineering. There are many image enhancement techniques out there, let us look at one that uses a function which commonly is seen in neural networks&lt;/p&gt;
&lt;h1 id="sigmoid-function"&gt;Sigmoid function&lt;/h1&gt;
&lt;p&gt;For all code below we will need &lt;code&gt;matplotlib.pyplot, skimage&lt;/code&gt; and &lt;code&gt;numpy&lt;/code&gt;. &lt;code&gt;skimage&lt;/code&gt; is my preference of image processing library, I find it easy to understand and, if you want to modify something, you can always look under the hood of any function.&lt;/p&gt;
&lt;p&gt;So, we will need
&lt;code&gt;python
from matplotlib import pyplot as plt
%matplotlib inline&lt;/code&gt;
for plotting,
```python
from skimage.data import astronaut
image = astronaut()&lt;/p&gt;
&lt;p&gt;from skimage.util import img_as_float64  # make image in range [0..255], 8-bit integers
```
for image, image datatype adjustment and for some feature visualization, respectively.&lt;/p&gt;
&lt;p&gt;Now, time for some visualization.
&lt;code&gt;python
plt.figure(figsize=(10,9))
plt.imshow(image)
plt.axis('off');&lt;/code&gt;&lt;/p&gt;
&lt;figure&gt;
  &lt;img src="https://iliailmer.github.io/images/enhancement-images/astronaut.png?raw=true" alt="astronaut"/&gt;
  &lt;figcaption&gt;Our base image, astronaut.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Let's make sure we have our sigmoid function correctly defined:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;python
def sigmoid(x):
    return 1/(1+np.exp(-x))&lt;/code&gt;&lt;/p&gt;
&lt;figure&gt;
  &lt;img src="https://iliailmer.github.io/images/enhancement-images/sigmoid.png" alt="sigmoid"/&gt;
  &lt;figcaption&gt;A simple sigmoid.&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;!--![](/assets/post_imgs/enhancement-images/sigmoid.png?raw=true)--&gt;

&lt;p&gt;So, how do we use it to enhance the image? Well, let's look at the code:
```python
image = astronaut()&lt;/p&gt;
&lt;p&gt;image_ = np.zeros_like(image, dtype="float64")
def sigmoid(x):
    return 1/(1+np.exp(-x))&lt;/p&gt;
&lt;p&gt;def sigm_enh(I, alpha, beta):
    I = img_as_float64(I)
    I_out = I&lt;em&gt;sigmoid(alpha&lt;/em&gt;(I-beta))#
    return I_out&lt;/p&gt;
&lt;p&gt;for i in range(3):
    image_[...,i] = sigm_enh(image[...,i],  2, 50)#float(image.mean()))&lt;/p&gt;
&lt;p&gt;fig, ax = plt.subplots(nrows=1, ncols = 2, figsize=(20,9))
ax[0].axis("off")
ax[0].imshow(astronaut())
ax[1].axis("off")
ax[1].imshow(rescale(image_,255))
```
and the result:&lt;/p&gt;
&lt;figure&gt;
  &lt;img src="https://iliailmer.github.io/images/enhancement-images/astro_sigmoid_dark.png?raw=true" alt="sigmoid_enh1"/&gt;
  &lt;figcaption&gt;Application of the code above.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;figure&gt;
  &lt;img src="https://iliailmer.github.io/images/enhancement-images/astro_sigmoid_bright.png?raw=true" alt="sigmoid_enh2"/&gt;
  &lt;figcaption&gt;Application of the code above with $\alpha = -2,~\beta=0.1$ and the result of rescaled to be between 0 and 255 for display.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;This is a simple way to bring image brightness up or down, especially comparing the results to some sort of metric (say, signal-to-noise ratio, or mean-squared error). In a different post, I will show a measure of image quality that our computer vision prof showed us (it's pretty cool, but has its own quirks).&lt;/p&gt;
&lt;p&gt;We should try to do a little better/advanced with image enhancement. A function introduced in &lt;a href="https://www.researchgate.net/profile/Vikrant_Bhateja2/publication/267338917_Mammographic_Image_Enhancement_using_Double_Sigmoid_Transformation_Function/links/544de7cb0cf2d6347f45d0d0/Mammographic-Image-Enhancement-using-Double-Sigmoid-Transformation-Function.pdf"&gt;this paper&lt;/a&gt; dubbed "double sigmoid" looks something like this&lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\( \sigma_{double} = \mathrm{sign}(x-x_1) \exp \left(1- \frac{(x-x_1)^2}{s}\right)\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;And the plot of it
&lt;code&gt;python
x = np.linspace(-10, 10, num=100)
plt.plot(x, double_sigmoid(x,0,2))&lt;/code&gt;&lt;/p&gt;
&lt;figure&gt;
  &lt;img src="https://iliailmer.github.io/images/enhancement-images/double_sigmoid_sample.png" alt="sigmoid_enh2"/&gt;
&lt;/figure&gt;

&lt;p&gt;which is similar to two sigmoids complementing each other. Using the technique from the paper on a colored image, we need to be careful because this method is very sensitive to input parameters.
```python
image = astronaut()&lt;/p&gt;
&lt;p&gt;image_ = np.zeros_like(image, dtype="float64")&lt;/p&gt;
&lt;p&gt;def double_sigmoid(x, x_1, s):
    return np.sign(x - x_1) * (1 - np.exp(-((x - x_1) / s) ** 2))&lt;/p&gt;
&lt;p&gt;def double_sigm_enh(I, x_1, k, s, b):
    a = 1 / (double_sigmoid(k * (1 - b), x_1, s) - double_sigmoid(-k * (1 + b), x_1, s))
    I_out = a * (double_sigmoid(k * (I - b), x_1, s) - double_sigmoid(-k * (I + b), x_1, s))
    return I_out&lt;/p&gt;
&lt;p&gt;for i in range(3):
    image_[...,i] = double_sigm_enh(image[...,i].astype("float64"), k=0.9, b=0.0, x_1=0, s=100)&lt;/p&gt;
&lt;p&gt;fig, ax = plt.subplots(nrows=1, ncols = 2, figsize=(20,9))
ax[0].axis("off")
ax[0].imshow(astronaut())
ax[1].axis("off")
ax[1].imshow(rescale(image_,255))
```&lt;/p&gt;
&lt;p&gt;This can also be applied to grey-level images. The problem with this method of enhancement is that it heavily relies on a careful choice of parameters and is very sensitive to their values.&lt;/p&gt;
&lt;p&gt;I really like that we can always find interesting applications of mathematical functions for image quality enhancement. In the next post I plan to talk about a measure that can be used to describe image quality.&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="Posts"></category><category term="image enhancement"></category></entry></feed>