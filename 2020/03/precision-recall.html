
<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="HandheldFriendly" content="True" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta name="robots" content="index, follow" />

  <link
    href="https://fonts.googleapis.com/css2?family=Source+Code+Pro:ital,wght@0,400;0,700;1,400&family=Source+Sans+Pro:ital,wght@0,300;0,400;0,700;1,400&display=swap"
    rel="stylesheet">

  <link rel="stylesheet" type="text/css" href="https://iliailmer.github.io/theme/stylesheet/style.min.css">

  <link id="dark-theme-style" rel="stylesheet" type="text/css"   media="(prefers-color-scheme: dark)"      href="https://iliailmer.github.io/theme/stylesheet/dark-theme.min.css">

  <link id="pygments-dark-theme" rel="stylesheet" type="text/css"      media="(prefers-color-scheme: dark)"      href="https://iliailmer.github.io/theme/pygments/monokai.min.css">
  <link id="pygments-light-theme" rel="stylesheet" type="text/css"     media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"      href="https://iliailmer.github.io/theme/pygments/emacs.min.css">

  <link rel="stylesheet" href="https://iliailmer.github.io/theme/tipuesearch/tipuesearch.min.css" />

  <link rel="stylesheet" type="text/css" href="https://iliailmer.github.io/theme/font-awesome/css/fontawesome.css">
  <link rel="stylesheet" type="text/css" href="https://iliailmer.github.io/theme/font-awesome/css/brands.css">
  <link rel="stylesheet" type="text/css" href="https://iliailmer.github.io/theme/font-awesome/css/solid.css">


  <link href="https://iliailmer.github.io/feeds/all.atom.xml" type="application/atom+xml" rel="alternate"
    title="Ilia Ilmer Atom">


  <link rel="shortcut icon" href="https://iliailmer.github.io/images/favicon.ico" type="image/x-icon">
  <link rel="icon" href="https://iliailmer.github.io/images/favicon.ico" type="image/x-icon">

<!-- Google Analytics -->
<script type="text/javascript">
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-131502498-2', 'auto');
  ga('send', 'pageview');
</script>
<!-- End Google Analytics -->

  <!-- Chrome, Firefox OS and Opera -->
  <meta name="theme-color" content="#333">
  <!-- Windows Phone -->
  <meta name="msapplication-navbutton-color" content="#333">
  <!-- iOS Safari -->
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <!-- Microsoft EDGE -->
  <meta name="msapplication-TileColor" content="#333">


<meta name="author" content="Ilia Ilmer" />
<meta name="description" content="In this post, I put together an interesting example of what to do with imbalanced datasets and why precision and recall matter. Introduction The following is part of a Machine learning assignment I had to do while at CUNY. This particular example illustrates quite well the importance of understanding various …" />
<meta name="keywords" content="machine learning, logistic regression, python, scikit-learn, statistical learning">


  <meta property="og:site_name" content="Ilia Ilmer"/>
  <meta property="og:title" content="Three Ways to Deal With Imbalance"/>
  <meta property="og:description" content="In this post, I put together an interesting example of what to do with imbalanced datasets and why precision and recall matter. Introduction The following is part of a Machine learning assignment I had to do while at CUNY. This particular example illustrates quite well the importance of understanding various …"/>
  <meta property="og:locale" content="en_US"/>
  <meta property="og:url" content="https://iliailmer.github.io/2020/03/precision-recall.html"/>
  <meta property="og:type" content="article"/>
  <meta property="article:published_time" content="2020-03-02 00:00:00-05:00"/>
  <meta property="article:modified_time" content=""/>
  <meta property="article:author" content="https://iliailmer.github.io/author/ilia-ilmer.html">
  <meta property="article:section" content="Posts"/>
  <meta property="article:tag" content="machine learning"/>
  <meta property="article:tag" content="logistic regression"/>
  <meta property="article:tag" content="python"/>
  <meta property="article:tag" content="scikit-learn"/>
  <meta property="article:tag" content="statistical learning"/>
  <meta property="og:image" content="https://iliailmer.github.io/images/compressed.jpeg">

  <title>Ilia Ilmer &ndash; Three Ways to Deal With Imbalance</title>

</head>

<body >
  <aside>
    <div>
      <a href="https://iliailmer.github.io/">
        <img src="https://iliailmer.github.io/images/compressed.jpeg" alt="Ilia Ilmer" title="Ilia Ilmer">
      </a>

      <h1>
        <a href="https://iliailmer.github.io/">Ilia Ilmer</a>
      </h1>

<p>Algorithms and Coffee</p>
      <form class="navbar-search" action="https://iliailmer.github.io/search.html" role="search">
        <input type="text" name="q" id="tipue_search_input" placeholder="Search...">
      </form>

      <nav>
        <ul class="list">


          <li>
            <a target="_self"
              href="https://iliailmer.github.io/pages/about.html#about">
              About
            </a>
          </li>
          <li>
            <a target="_self"
              href="https://iliailmer.github.io/pages/publications.html#publications">
              Publications
            </a>
          </li>
          <li>
            <a target="_self"
              href="https://iliailmer.github.io/pages/software.html#software">
              Software
            </a>
          </li>
          <li>
            <a target="_self"
              href="https://iliailmer.github.io/pages/talks.html#talks">
              Talks
            </a>
          </li>

        </ul>
      </nav>

      <ul class="social">
        <li>
          <a  class="sc-github" href="https://github.com/iliailmer" target="_blank">
            <i class="fab fa-github"></i>
          </a>
        </li>
        <li>
          <a  class="sc-gitlab" href="https://gitlab.com/iliailmer" target="_blank">
            <i class="fab fa-gitlab"></i>
          </a>
        </li>
        <li>
          <a  class="sc-linkedin" href="https://linkedin.com/in/iilmer" target="_blank">
            <i class="fab fa-linkedin"></i>
          </a>
        </li>
      </ul>
    </div>

  </aside>
  <main>

    <nav>
      <a href="https://iliailmer.github.io/">Home</a>

      <a href="/files/resume.pdf">CV</a>

      <a href="https://iliailmer.github.io/feeds/all.atom.xml">Atom</a>

    </nav>

<article class="single">
  <header>
    
    <h1 id="precision-recall">Three Ways to Deal With Imbalance</h1>
    <p>
      Posted on Mon 02 March 2020 in <a href="https://iliailmer.github.io/category/posts.html">Posts</a>

    </p>
  </header>


  <nav class="toc">
    true
  </nav>
  <div>
    <p>In this post, I put together an interesting example of what to do with imbalanced datasets and why precision and recall matter.</p>
<h2 id="introduction">Introduction</h2>
<p>The following is part of a Machine learning assignment I had to do while at CUNY. This particular example illustrates quite well the importance of understanding various measures of model quality such as accuracy, precision, recall, etc.</p>
<p>The idea is to predict whether a client will have a credit card default given some simple data. An insult to injury is a heavily imbalanced dataset: 97% of examples are "Yes"-labeled, making it difficult to train a good classifier.</p>
<!-- 1. **Stratified sampling**. Split the `default` dataset into `df_train` (60%), `df_validation`(20%), and `df_test` (20%) so that all sets have the same percentage of positive cases. 
2. **Augment data with oversampling.** Increase the amount of positive cases by adding duplicates randomly sampled from the positive class. Create a new data frame `df_train_over` where the number of positive cases is equal to the number of negative cases. 
3. **Augment data with undersampling**. Randomly remove samples from the negative class. Create a new data frame `df_train_under` where the number of negative cases is equal to the number of positive cases. 
4. Train a logistic regression model on each of the three training sets: `df_train`, `df_train_over`, `df_train_under`. 
5. For each model, compute the **confusion matrix**, **precision score**, and **recall score** on `df_validation. Decide which model has the best performance and explain why.  Please read this article to learn the definitions.
6. Apply the best model to `df_test` and compute the **confusion matrix**, **precision score**, and **recall score**. Are the results similar to those from `df_validation`? -->

<p>We will dive into the solution, but first, some imports:</p>
<pre><code class="language-python">import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
%matplotlib inline
import numpy as np
import gc
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, precision_score, recall_score
from sklearn.linear_model import LogisticRegressionCV, LogisticRegression
plt.style.use('fivethirtyeight')
</code></pre>
<p>A plotting helper:</p>
<pre><code class="language-py">def plot_cm(y_pred, y_true):
    &quot;&quot;&quot;Plot confusion matrix based on
       true vs. predicted values.&quot;&quot;&quot;
    cm = confusion_matrix(y_true=y_true, y_pred=y_pred)
    prec = precision_score(y_true=y_true, y_pred=y_pred)
    rec = recall_score(y_true=y_true, y_pred=y_pred)
    sns.heatmap(cm, annot=True)
    plt.title(f&quot;Precision: {prec:.2f}, Recall: {rec:.2f}&quot;)
</code></pre>
<p>Finally, reading the <a href="https://github.com/JWarmenhoven/ISLR-python/blob/master/Notebooks/Data/Default.xlsx?raw=true">data</a>:</p>
<pre><code class="language-python">df = pd.read_excel(&quot;Default.xlsx&quot;, header=0).iloc[:, 1:]

# convert strings to binary int32 0,1 values

df['default'] = df['default'].apply(lambda x: 0 if x == 'No' else 1).astype(
    np.int32)
df['student'] = df['student'].apply(lambda x: 0 if x == 'No' else 1).astype(
    np.int32)
X = df.drop(['default'], axis=1)
y = df['default']
</code></pre>
<p>To save memory: convert applicable columns from float64(double) to float32(float). This may help with much bigger datasets, this one is relatively small, though. Applicable here means max value of a column falls within the limits of the float32 range:</p>
<pre><code class="language-py">for column in df.columns:
    if df[column].values.max() &lt; np.finfo(np.float32).max:
        if df[column].values.min() &gt; np.finfo(np.float32).min:
            df[column] = df[column].values.astype(np.float32)
# garbage collector
gc.collect()
</code></pre>
<p>Let's look at the distribution of the target value:</p>
<pre><code class="language-python">ax = sns.countplot(data=df, x='default')
</code></pre>
<p><img alt="png" src="https://iliailmer.github.io/images/2020-03-02-precision-recall/output_5_0.png" /></p>
<p>The histogram above verifies the problem: the data is highly imbalanced. To train a linear regression classifier, we will try to remedy the issue with three approaches:</p>
<ol>
<li>We sample a training, validation, and testing subsets in a <strong><em>stratified</em></strong> manner, that is, preserving the ratio between "0" and "1" labels.</li>
<li>We will <strong><em>oversample</em></strong> the less represented class: "1", or "Yes"-labeled default examples.</li>
<li>We will <strong><em>undersample</em></strong> the overrepresented class: "0".</li>
</ol>
<h2 id="stratified-sampling">Stratified Sampling</h2>
<p>To sample in a way that the imbalance is preserved (stratified) we will pass an argument <code>stratify</code> to the <code>train_test_split</code> function from <code>sklearn</code>. Specifically, we will pass the column of labels <code>df['default']</code> so that the function determines the exact distribution.</p>
<pre><code class="language-python">df_train, df_test, y_train, y_test = train_test_split(X,
                                                      y,
                                                      random_state=42,
                                                      stratify=df['default'],
                                                      train_size=0.6)

df_val, df_test, y_val, y_test = train_test_split(df_test,
                                                  y_test,
                                                  random_state=42,
                                                  stratify=y_test,
                                                  train_size=0.5)
</code></pre>
<p>The plot below will illustrate the distribution of labels in the sampled data.</p>
<pre><code class="language-python">fig, ax = plt.subplots(ncols=3, figsize=(12, 4))
fig.suptitle(&quot;Left to right: train, val, test label counts.&quot;)
for i, data in zip(range(3), (y_train, y_val, y_test)):
    sns.countplot(x=data, ax=ax[i])
</code></pre>
<p><img alt="png" src="https://iliailmer.github.io/images/2020-03-02-precision-recall/output_11_0.png" /></p>
<pre><code class="language-python">print(f'Train data to original dataset: {len(df_train)/len(X) * 100}%')
print(f'Validation data to original dataset: {len(df_val)/len(X) * 100}%')
print(f'Test data to original dataset: {len(df_test)/len(X) * 100}%')

print(f'\nNegative labels in original data: {len(X[y==0])/len(X) * 100 :.3}%')
print(f'Negative labels in train data: {(len(df_train[y_train==0])/len(df_train) * 100) :.3}%')
print(f'Negative labels in validation data: {(len(df_val[y_val==0])/len(df_val) * 100) :.3}%')
print(f'Negative labels in test data: {(len(df_test[y_test==0])/len(df_test) * 100) :.3}%')

</code></pre>
<pre><code>Train data to original dataset: 60.0%
Validation data to original dataset: 20.0%
Test data to original dataset: 20.0%

Negative labels in original data: 96.7%
Negative labels in train data: 96.7%
Negative labels in validation data: 96.7%
Negative labels in test data: 96.7%
</code></pre>
<h2 id="oversampling">Oversampling</h2>
<p>For oversampling we will use a package called <code>imbalanced-learn</code> available <a href="https://pypi.org/project/imbalanced-learn/">from PyPI</a>. It has built-in classes for various over- and under-sampling methods. We will use basic <code>RandomOverSampler</code> and <code>RandomUnderSampler</code> classes.</p>
<p>The package is built with similarities to other <code>sklearn</code> conventions, so calling <code>fit</code> methods will give us the necessary results.</p>
<pre><code class="language-python">from imblearn.over_sampling import RandomOverSampler

ros = RandomOverSampler(random_state=42)  # initialize
df_train_over, y_train_over = ros.fit_sample(
    df_train, y=y_train)  # resample training data
ax = sns.countplot(x=y_train_over)  # plot value counts for the labels
t = plt.suptitle(&quot;Oversampled value counts.&quot;)
</code></pre>
<p><img alt="png" src="https://iliailmer.github.io/images/2020-03-02-precision-recall/output_15_0.png" /></p>
<h2 id="underspamling">Underspamling</h2>
<pre><code class="language-python">from imblearn.under_sampling import RandomUnderSampler

rus = RandomUnderSampler(random_state=42, )  # initialize
df_train_under, y_train_under = rus.fit_sample(df_train, y=y_train)  # resample
ax = sns.countplot(x=y_train_under)  # plot
t = plt.suptitle(&quot;Undersampled value counts.&quot;)
</code></pre>
<p><img alt="png" src="https://iliailmer.github.io/images/2020-03-02-precision-recall/output_17_0.png" /></p>
<h2 id="train-naively-without-stratification">Train naively without stratification</h2>
<p>Let us first train logistic regression model on a similarly split data without stratification.</p>
<pre><code class="language-python">df_train_naive, df_test_naive, y_train_naive, y_test_naive = train_test_split(
    X, y, random_state=42, train_size=0.6)

df_val_naive, df_test_naive, y_val_naive, y_test_naive = train_test_split(
    df_test_naive, y_test_naive, random_state=42, train_size=0.6)
</code></pre>
<pre><code class="language-python">logreg = LogisticRegression(penalty='none', max_iter=1e4, random_state=42)
logreg.fit(df_train_naive, y_train_naive)
y_pred = logreg.predict(df_val_naive)

plot_cm(y_val_naive, y_pred)
</code></pre>
<p><img alt="png" src="https://iliailmer.github.io/images/2020-03-02-precision-recall/output_21_0.png" /></p>
<p>We observe zero precision and zero recall scores and the model overfits on the '0' class, which is expected and is bad.</p>
<h2 id="train-on-stratified">Train on Stratified</h2>
<p>Below we train on the stratified data. We observe a better recall and precision scores and the predicted result on validation data follows the distribution of labels as in the training data (note that this heuristic is absolutely non-strict and does not necessarily indicate whether a model is good or bad).</p>
<pre><code class="language-python">logreg = LogisticRegression(penalty='none', max_iter=1e4, random_state=42)
logreg.fit(df_train, y_train)
y_pred = logreg.predict(df_val)

plot_cm(y_val, y_pred)
</code></pre>
<p><img alt="png" src="https://iliailmer.github.io/images/2020-03-02-precision-recall/output_25_0.png" /></p>
<pre><code class="language-python">ax = plt.subplot()
ax = sns.countplot(y_pred, ax=ax)
</code></pre>
<p><img alt="png" src="https://iliailmer.github.io/images/2020-03-02-precision-recall/output_26_0.png" /></p>
<h2 id="train-on-oversampled">Train on Oversampled</h2>
<p>When training on Oversampled data we get a very high precision score but lose the recall score.</p>
<pre><code class="language-python">logreg = LogisticRegression(penalty='none', max_iter=1e4, random_state=42)
logreg.fit(df_train_over, y_train_over)
y_pred = logreg.predict(df_val)

plot_cm(y_val, y_pred)
</code></pre>
<p><img alt="png" src="https://iliailmer.github.io/images/2020-03-02-precision-recall/output_29_0.png" /></p>
<pre><code class="language-python">y_pred = logreg.predict(df_test)

plot_cm(y_test, y_pred)
</code></pre>
<p><img alt="png" src="https://iliailmer.github.io/images/2020-03-02-precision-recall/output_30_0.png" /></p>
<h2 id="train-on-undersampled">Train on Undersampled</h2>
<p>A similar behavior occurs in the undersampled case, we see increase in Precision compared to naive and stratified cases, but both precision and recall are a bit lower that oversampled case.</p>
<pre><code class="language-python">logreg = LogisticRegression(penalty='none', max_iter=1e4, random_state=42)
logreg.fit(df_train_under, y_train_under)
y_pred = logreg.predict(df_val)

plot_cm(y_val, y_pred)
</code></pre>
<p><img alt="png" src="https://iliailmer.github.io/images/2020-03-02-precision-recall/output_33_0.png" /></p>
<h2 id="conclusion">Conclusion</h2>
<p>In this assignment, we considered a problem of default prediction for a credit card holder. We omitted most of preliminary data analysis and instead focused on basic model building for a highly imbalanced dataset. The proportion of negative labels is 97% out of all given data. Let us briefly outline meaning behind precision and recall scores.</p>
<p><strong>Precision score</strong> shows the ratio of true positive predictions over all positive predictions regardless if they were true or false. If the number of true positive predictions is negligible compared to false positives then precision is low.</p>
<p><strong>Recall score</strong>, on the other hand, shows the ratio of true positives versus the sum of true positive and false negative predictions. That is, if the prediction's number of true positive cases is trumped by the number of false negative cases, the recall score will be higher.</p>
<p>Card default is essentially the inability to pay off the card's balance. In this case, we are not willing to accept a false negative prediction: if we forecast that the default does not happen and in reality it does then we (the bank) are in the losing position. On the other hand, the false positive case does not affect us because in the worst case the cardholder pays off their debt and the default does not happen.</p>
<p>Since we want to be as effective as possible in our prediction, we must recommend a model with a higher recall score, which in this case is a stratified logistic recall score model.</p>
<pre><code class="language-python">logreg = LogisticRegression(penalty='none', max_iter=1e4, random_state=42)
logreg.fit(df_train, y_train)
y_pred = logreg.predict(df_val)

plot_cm(y_val, y_pred)
</code></pre>
<p><img alt="png" src="https://iliailmer.github.io/images/2020-03-02-precision-recall/output_36_0.png" /></p>
<pre><code class="language-python">y_pred = logreg.predict(df_test)

plot_cm(y_test, y_pred)
</code></pre>
<p><img alt="png" src="https://iliailmer.github.io/images/2020-03-02-precision-recall/output_37_0.png" /></p>
  </div>
  <div class="tag-cloud">
    <p>
      <a href="https://iliailmer.github.io/tag/machine-learning.html">machine learning</a>
      <a href="https://iliailmer.github.io/tag/logistic-regression.html">logistic regression</a>
      <a href="https://iliailmer.github.io/tag/python.html">python</a>
      <a href="https://iliailmer.github.io/tag/scikit-learn.html">scikit-learn</a>
      <a href="https://iliailmer.github.io/tag/statistical-learning.html">statistical learning</a>
    </p>
  </div>





</article>

    <footer>
<p>
  &copy; 2021  - This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/deed.en_US" target="_blank">Creative Commons Attribution-ShareAlike</a>
</p>
<p>
Built with <a href="http://getpelican.com" target="_blank">Pelican</a> using <a href="http://bit.ly/flex-pelican" target="_blank">Flex</a> theme
  <span class="footer-separator">|</span>
  Switch to the <a href="javascript:void(0)" onclick="theme.switch(`dark`)">dark</a> | <a href="javascript:void(0)" onclick="theme.switch(`light`)">light</a> | <a href="javascript:void(0)" onclick="theme.switch(`browser`)">browser</a> theme
  <script id="dark-theme-script"
          src="https://iliailmer.github.io/theme/dark-theme/dark-theme.min.js"
          data-enable-auto-detect-theme="True"
          data-default-theme="light"
          type="text/javascript">
  </script>
</p><p>
  <a rel="license"
     href="http://creativecommons.org/licenses/by-sa/4.0/"
     target="_blank">
    <img alt="Creative Commons License"
         title="Creative Commons License"
         style="border-width:0"
           src="https://i.creativecommons.org/l/by-sa/4.0/80x15.png"
         width="80"
         height="15"/>
  </a>
</p>    </footer>
  </main>




<script type="application/ld+json">
{
  "@context" : "http://schema.org",
  "@type" : "Blog",
  "name": " Ilia Ilmer ",
  "url" : "https://iliailmer.github.io",
  "image": "https://iliailmer.github.io/images/compressed.jpeg",
  "description": ""
}
</script>

</body>

</html>